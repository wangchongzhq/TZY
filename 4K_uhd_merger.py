#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
4Kè¶…é«˜æ¸…ç›´æ’­æºåˆå¹¶è½¬æ¢å·¥å…·
åŠŸèƒ½ï¼šä»4K_uhd_channels.txtä¸­æå–.m3uç›´æ’­æºURLï¼Œåˆå¹¶å†…å®¹ï¼Œè½¬æ¢ä¸ºé¢‘é“åç§°,URLæ ¼å¼çš„.txtæ–‡ä»¶
ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2024-01-18
"""

import os
import re
import sys
import time
import threading
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

class UHDChannelMerger:
    """4Kè¶…é«˜æ¸…ç›´æ’­æºåˆå¹¶å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆå¹¶å™¨"""
        self.input_file = "4K_uhd_channels.txt"
        self.output_file = "4K_uhd_hb.txt"
        self.url_pattern = re.compile(r'(https?://|file://)[^\s"\'\n]+\.m3u')
        self.encoding_patterns = ['utf-8-sig', 'utf-8', 'gbk', 'gb2312', 'iso-8859-1']
        self.visited_urls = set()
        self.channel_map = {}  # ç”¨äºå»é‡å’Œå­˜å‚¨é¢‘é“åç§°ä¸URLçš„æ˜ å°„ {url: channel_name}
        self.total_channels = 0
        self.success_channels = 0
        self.failed_channels = 0
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.lock = threading.Lock()
        self.max_workers = min(10, os.cpu_count() * 2)  # çº¿ç¨‹æ± å¤§å°
    
    def set_input_output_files(self, input_file, output_file):
        """è®¾ç½®è¾“å…¥è¾“å‡ºæ–‡ä»¶"""
        self.input_file = input_file
        self.output_file = output_file
    
    def extract_m3u_urls(self):
        """ä»è¾“å…¥æ–‡ä»¶ä¸­æå–.m3u URL"""
        print(f"ï¿½ æ­£åœ¨è¯»å–è¾“å…¥æ–‡ä»¶: {self.input_file}")
        urls = set()  # ä½¿ç”¨é›†åˆè‡ªåŠ¨å»é‡
        
        try:
            with open(self.input_file, 'r', encoding='utf-8-sig') as f:
                content = f.read()
                
                # æå–HTTP/HTTPS URL
                http_urls = re.findall(r'https?://[^\s"\'\n]+\.m3u', content, re.IGNORECASE)
                urls.update(http_urls)
                
                # æå–æœ¬åœ°æ–‡ä»¶URL
                file_urls = re.findall(r'file://[^\s"\'\n]+\.m3u', content, re.IGNORECASE)
                urls.update(file_urls)
            
            urls = sorted(urls)
            print(f"ğŸ“Š æ‰¾åˆ° {len(urls)} ä¸ª.m3uç›´æ’­æºURL")
            
            # æ˜¾ç¤ºæ‰¾åˆ°çš„URL
            for i, url in enumerate(urls, 1):
                print(f"   {i}. {url}")
            
            return urls
            
        except FileNotFoundError:
            print(f"âŒ è¾“å…¥æ–‡ä»¶ {self.input_file} ä¸å­˜åœ¨")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ è¯»å–è¾“å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            sys.exit(1)
    
    def detect_encoding(self, file_path):
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        for encoding in self.encoding_patterns:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    f.read()
                return encoding
            except UnicodeDecodeError:
                continue
        return 'utf-8'  # é»˜è®¤ç¼–ç 
    
    def download_m3u_content(self, url):
        """ä¸‹è½½M3Uå†…å®¹ï¼ˆæ”¯æŒHTTPå’Œæœ¬åœ°æ–‡ä»¶ï¼‰"""
        print(f"ğŸŒ æ­£åœ¨è·å–: {url}")
        
        if url.startswith('file://'):
            # å¤„ç†æœ¬åœ°æ–‡ä»¶
            try:
                # è½¬æ¢file:// URLä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
                file_path = url[7:]  # ç§»é™¤file://å‰ç¼€
                
                # Windowsè·¯å¾„ä¿®å¤
                if file_path.startswith('/'):
                    file_path = file_path[1:]  # ç§»é™¤å¼€å¤´çš„/
                file_path = file_path.replace('/', '\\')
                
                # æ£€æµ‹æ–‡ä»¶ç¼–ç 
                encoding = self.detect_encoding(file_path)
                
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                
                print(f"âœ… æˆåŠŸè¯»å–æœ¬åœ°æ–‡ä»¶: {file_path}")
                return content
                
            except Exception as e:
                print(f"âŒ è¯»å–æœ¬åœ°æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                return None
        else:
            # å¤„ç†HTTP/HTTPS URL
            retries = 0
            max_retries = 3
            
            while retries < max_retries:
                try:
                    response = self.session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        # å°è¯•å¤šç§ç¼–ç 
                        for encoding in self.encoding_patterns:
                            try:
                                content = response.content.decode(encoding)
                                print(f"âœ… æˆåŠŸä¸‹è½½: {url}")
                                return content
                            except UnicodeDecodeError:
                                continue
                        
                        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç¼–ç 
                        content = response.text
                        print(f"âœ… æˆåŠŸä¸‹è½½ï¼ˆé»˜è®¤ç¼–ç ï¼‰: {url}")
                        return content
                    else:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {url}")
                        retries += 1
                        if retries < max_retries:
                            print(f"ğŸ”„ é‡è¯• ({retries}/{max_retries})...")
                            time.sleep(2)
                
                except requests.RequestException as e:
                    print(f"âŒ è¯·æ±‚é”™è¯¯: {e} - {url}")
                    retries += 1
                    if retries < max_retries:
                        print(f"ğŸ”„ é‡è¯• ({retries}/{max_retries})...")
                        time.sleep(2)
            
            print(f"ğŸš« æ”¾å¼ƒä¸‹è½½: {url}")
            return None
    
    def parse_m3u_content(self, content, source_url):
        """è§£æM3Uå†…å®¹ï¼Œæå–é¢‘é“ä¿¡æ¯ï¼ˆåªä¿ç•™é¢‘é“åç§°å’ŒURLï¼‰"""
        parsed_channels = []
        
        try:
            lines = content.splitlines()
            i = 0
            while i < len(lines):
                line = lines[i].strip()
                
                if line.startswith('#EXTINF:'):
                    # æå–é¢‘é“åç§°ï¼ˆé€šå¸¸åœ¨æœ€åä¸€ä¸ªé€—å·åï¼‰
                    if ',' in line:
                        channel_name = line.split(',')[-1].strip()
                    else:
                        channel_name = f"Channel_{len(parsed_channels) + 1}"
                    
                    # ä¸‹ä¸€è¡Œåº”è¯¥æ˜¯URL
                    if i + 1 < len(lines):
                        url_line = lines[i + 1].strip()
                        if url_line.startswith(('http://', 'https://')):
                            channel_url = url_line
                            
                            # ä½¿ç”¨URLä½œä¸ºé”®ï¼Œé¢‘é“åç§°ä½œä¸ºå€¼ï¼Œç”¨äºå»é‡
                            with self.lock:
                                if channel_url not in self.channel_map:
                                    self.channel_map[channel_url] = channel_name
                                    parsed_channels.append((channel_name, channel_url))
                                    print(f"    ğŸ“¡ é¢‘é“: {channel_name} -> URL: {channel_url}")
                                else:
                                    print(f"    âš ï¸  è·³è¿‡é‡å¤é¢‘é“ (URLå·²å­˜åœ¨): {channel_name} -> URL: {channel_url}")
                            
                            i += 2  # è·³è¿‡URLè¡Œ
                            continue
                    
                i += 1
            
            print(f"ï¿½ ä»{source_url}è§£æåˆ° {len(parsed_channels)} ä¸ªé¢‘é“")
            return parsed_channels
            
        except Exception as e:
            print(f"âŒ è§£æM3Uå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def process_single_m3u(self, url):
        """å¤„ç†å•ä¸ªM3Uæ–‡ä»¶"""
        try:
            # æ£€æŸ¥URLæ˜¯å¦å·²å¤„ç†è¿‡
            if url in self.visited_urls:
                print(f"ğŸ”„ è·³è¿‡å·²å¤„ç†çš„URL: {url}")
                return []
            
            self.visited_urls.add(url)
            
            # ä¸‹è½½æˆ–è¯»å–M3Uå†…å®¹
            content = self.download_m3u_content(url)
            
            if not content:
                print(f"ğŸš« æ— æ³•è·å–{url}çš„å†…å®¹")
                return []
            
            # è§£æM3Uå†…å®¹
            channels = self.parse_m3u_content(content, url)
            
            return channels
            
        except Exception as e:
            print(f"âŒ å¤„ç†{url}æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def save_results(self):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°æ–‡ä»¶ï¼ˆæ ¼å¼ï¼šé¢‘é“åç§°,URLï¼‰"""
        try:
            # ä»channel_mapä¸­è·å–æ‰€æœ‰é¢‘é“ï¼ˆå·²è‡ªåŠ¨å»é‡ï¼‰
            unique_channels = [f"{name},{url}" for url, name in self.channel_map.items()]
            unique_channels.sort()  # æŒ‰é¢‘é“åç§°æ’åº
            
            with open(self.output_file, 'w', encoding='utf-8-sig') as f:
                # å†™å…¥æ–‡ä»¶å¤´ä¿¡æ¯
                f.write("# 4Kè¶…é«˜æ¸…ç›´æ’­æºåˆå¹¶åˆ—è¡¨\n")
                f.write(f"# æ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# é¢‘é“æ€»æ•°: {len(unique_channels)}\n")
                f.write(f"# æ¥æº: {self.input_file}\n")
                f.write("\n")
                f.write("# é¢‘é“åˆ—è¡¨ï¼ˆæ ¼å¼ï¼šé¢‘é“åç§°,é¢‘é“URLï¼‰\n")
                f.write("\n")
                
                # å†™å…¥é¢‘é“ä¿¡æ¯
                for channel in unique_channels:
                    f.write(f"{channel}\n")
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(self.output_file) / 1024
            
            print(f"âœ… ä¿å­˜æˆåŠŸ!")
            print(f"ğŸ“ æ–‡ä»¶å: {self.output_file}")
            print(f"ğŸ“Š é¢‘é“æ•°: {len(unique_channels)}")
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
            
            # æ˜¾ç¤ºç¤ºä¾‹å†…å®¹
            print(f"\nğŸ“„ æ–‡ä»¶ç¤ºä¾‹å†…å®¹:")
            with open(self.output_file, 'r', encoding='utf-8-sig') as f:
                lines = f.readlines()[:10]  # åªæ˜¾ç¤ºå‰10è¡Œ
                for line in lines:
                    print(f"   {line.rstrip()}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            sys.exit(1)
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("ğŸš€ 4Kè¶…é«˜æ¸…ç›´æ’­æºåˆå¹¶è½¬æ¢å·¥å…·å¯åŠ¨")
        start_time = time.time()
        
        try:
            # 1. æå–M3U URL
            m3u_urls = self.extract_m3u_urls()
            
            if not m3u_urls:
                print("ğŸš« æ²¡æœ‰æ‰¾åˆ°.m3uç›´æ’­æºURL")
                sys.exit(1)
            
            # 2. ä¸‹è½½å¹¶è§£ææ‰€æœ‰M3Uå†…å®¹
            print("\nğŸ”„ å¼€å§‹åˆå¹¶å’Œè½¬æ¢ç›´æ’­æº...")
            print(f"âš¡ ä½¿ç”¨ {self.max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
                future_to_url = {
                    executor.submit(self.process_single_m3u, url): url 
                    for url in m3u_urls
                }
                
                # å¤„ç†ç»“æœ
                for future in as_completed(future_to_url):
                    url = future_to_url[future]
                    try:
                        future.result()  # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
                    except Exception as e:
                        print(f"âŒ å¤„ç†{url}æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            
            # 3. ç»Ÿè®¡ç»“æœ
            print("\nğŸ“Š åˆå¹¶ç»Ÿè®¡:")
            print(f"   æ€»å¤„ç†URLæ•°: {len(self.visited_urls)}")
            print(f"   å»é‡åé¢‘é“æ•°: {len(self.channel_map)}")
            
            if not self.channel_map:
                print("ğŸš« æ²¡æœ‰è§£æåˆ°ä»»ä½•é¢‘é“ä¿¡æ¯")
                sys.exit(1)
            
            # 4. ä¿å­˜ç»“æœ
            self.save_results()
            
            end_time = time.time()
            total_time = end_time - start_time
            
            print("\n" + "=" * 60)
            print(f"ğŸ† æ“ä½œå®Œæˆ!")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f} ç§’")
            print(f"ğŸ“ ç»“æœæ–‡ä»¶: {self.output_file}")
            print(f"ğŸ’¡ æç¤º: å¯ä»¥æ‰‹åŠ¨æˆ–é€šè¿‡å·¥ä½œæµå®šæœŸè¿è¡Œæ­¤è„šæœ¬")
            print("=" * 60)
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
            sys.exit(1)
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 6):
        print("âŒ éœ€è¦Python 3.6æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–åº“ requests")
        print("è¯·è¿è¡Œ: pip install requests")
        sys.exit(1)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='4Kè¶…é«˜æ¸…ç›´æ’­æºåˆå¹¶è½¬æ¢å·¥å…·')
    parser.add_argument('-i', '--input-file', default='4K_uhd_channels.txt', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output-file', default='4K_uhd_hb.txt', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # åˆ›å»ºåˆå¹¶å™¨å®ä¾‹å¹¶è¿è¡Œ
    merger = UHDChannelMerger()
    merger.set_input_output_files(args.input_file, args.output_file)
    merger.run()


if __name__ == "__main__":
    main()