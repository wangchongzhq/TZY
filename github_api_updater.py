#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GitHub APIæ–‡ä»¶æ›´æ–°å™¨
ç”¨äºé€šè¿‡GitHub APIç›´æ¥æ›´æ–°æ–‡ä»¶ï¼Œé¿å…git pushæ“ä½œå¸¦æ¥çš„å†²çªé—®é¢˜
"""

import os
import sys
import base64
import time
import json
import random
import logging
import requests
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("github_api_update.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GitHubAPIUpdater:
    def __init__(self, token, repo_owner, repo_name, branch="main", api_version="2022-11-28"):
        """åˆå§‹åŒ–GitHub APIæ›´æ–°å™¨"""
        self.token = token
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.branch = branch
        self.api_version = api_version
        self.base_url = "https://api.github.com"
        self.headers = {
            "Authorization": f"token {self.token}",
            "Accept": "application/vnd.github+json",
            "X-GitHub-Api-Version": self.api_version,
            "User-Agent": "GitHub-Actions-Tvzy-Update-Script"
        }
        
        # éªŒè¯å¿…è¦å‚æ•°
        if not self.token:
            raise ValueError("GitHub token cannot be empty")
        if not self.repo_owner or not self.repo_name:
            raise ValueError("Repository owner and name cannot be empty")
    
    def get_file_sha(self, file_path, max_retries=3):
        """
        è·å–æ–‡ä»¶çš„å½“å‰SHA
        å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›None
        """
        endpoint = f"/repos/{self.repo_owner}/{self.repo_name}/contents/{file_path}?ref={self.branch}"
        url = f"{self.base_url}{endpoint}"
        
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"Attempt {attempt}/{max_retries}: Getting SHA for file {file_path}")
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=15,
                    allow_redirects=True
                )
                
                # è®°å½•HTTPçŠ¶æ€ç 
                logger.info(f"HTTP Status Code: {response.status_code}")
                
                # æ–‡ä»¶å­˜åœ¨
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if "sha" in data:
                            sha = data["sha"]
                            logger.info(f"Successfully got SHA for {file_path}: {sha[:7]}...")
                            return sha
                        else:
                            logger.warning(f"SHA not found in response for {file_path}")
                    except json.JSONDecodeError:
                        logger.error(f"Failed to parse JSON response for {file_path}")
                        logger.debug(f"Response content: {response.text[:200]}...")
                
                # æ–‡ä»¶ä¸å­˜åœ¨
                elif response.status_code == 404:
                    logger.info(f"File {file_path} does not exist, will create new file")
                    return None
                
                # å¤„ç†å…¶ä»–é”™è¯¯
                else:
                    logger.error(f"Failed to get SHA for {file_path}, HTTP {response.status_code}")
                    logger.debug(f"Response content: {response.text[:200]}...")
                    
                    # å¤„ç†ç‰¹å®šé”™è¯¯
                    if response.status_code == 401:
                        logger.error("Authentication failed, check your GitHub token")
                        return None
                    elif response.status_code == 403:
                        logger.error("API rate limit or insufficient permissions (403)")
                        if "X-RateLimit-Reset" in response.headers:
                            reset_time = response.headers["X-RateLimit-Reset"]
                            logger.info(f"Rate limit resets at: {reset_time}")
                
            except requests.RequestException as e:
                logger.error(f"Request exception while getting SHA for {file_path}: {str(e)}")
            
            # é‡è¯•é€»è¾‘
            if attempt < max_retries:
                wait_time = attempt * 3  # çº¿æ€§é€€é¿
                logger.info(f"Waiting {wait_time} seconds before retry...")
                time.sleep(wait_time)
            
        logger.warning(f"All attempts to get SHA for {file_path} failed")
        return None
    
    def encode_file(self, file_path):
        """å°†æ–‡ä»¶ç¼–ç ä¸ºbase64"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                logger.error(f"File {file_path} does not exist")
                return None
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            logger.info(f"File {file_path} size: {file_size} bytes")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            if file_size == 0:
                logger.error(f"File {file_path} is empty")
                return None
            
            # ç¼–ç æ–‡ä»¶
            with open(file_path, 'rb') as f:
                content = f.read()
            encoded = base64.b64encode(content).decode('utf-8')
            logger.info(f"Successfully encoded {file_path} to base64, length: {len(encoded)} characters")
            return encoded
            
        except Exception as e:
            logger.error(f"Failed to encode file {file_path}: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            return None
    
    def upload_file(self, file_path, commit_message=None, max_retries=5, base_delay=2):
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°GitHubä»“åº“
        ä½¿ç”¨å¢å¼ºçš„æŒ‡æ•°é€€é¿ç­–ç•¥å’Œæ™ºèƒ½å†²çªæ£€æµ‹è¿›è¡Œé‡è¯•
        
        Args:
            file_path (str): è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            commit_message (str): æäº¤ä¿¡æ¯
            max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°
            base_delay (int): åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            bool: æ˜¯å¦ä¸Šä¼ æˆåŠŸ
        """
        endpoint = f"/repos/{self.repo_owner}/{self.repo_name}/contents/{file_path}"
        url = f"{self.base_url}{endpoint}"
        
        # ç¼–ç æ–‡ä»¶
        encoded_content = self.encode_file(file_path)
        if not encoded_content:
            logger.critical(f"Failed to encode file {file_path}, aborting upload")
            return False
        
        # ç”Ÿæˆæäº¤æ¶ˆæ¯
        if not commit_message:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            commit_message = f"è‡ªåŠ¨æ›´æ–°: {file_path} ({timestamp})"
        
        logger.info(f"ğŸ”„ Preparing to upload {file_path} with commit message: {commit_message}")
        logger.info(f"âš¡ Using enhanced conflict detection and smart retry strategy")
        
        last_conflict_time = None
        conflict_count = 0
        
        for attempt in range(1, max_retries + 1):
            try:
                # è·å–æœ€æ–°SHAï¼ˆåœ¨æ¯æ¬¡å°è¯•å‰é‡æ–°è·å–ä»¥é¿å…å†²çªï¼‰
                current_sha = self.get_file_sha(file_path, max_retries=3)
                if current_sha:
                    logger.info(f"ğŸ” Retrieved latest SHA: {current_sha[:7]}...")
                else:
                    logger.info(f"ğŸ“„ Will create new file: {file_path}")
                
                # æ„å»ºè¯·æ±‚æ•°æ®
                data = {
                    "message": commit_message,
                    "content": encoded_content,
                    "branch": self.branch
                }
                
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ SHAï¼ˆä¹è§‚å¹¶å‘æ§åˆ¶ï¼‰
                if current_sha:
                    data["sha"] = current_sha
                    logger.info(f"ğŸ“ Updating existing file with SHA-based optimistic concurrency control")
                
                # å‘é€è¯·æ±‚
                logger.info(f"ğŸš€ Attempt {attempt}/{max_retries}: Sending PUT request to update file")
                response = requests.put(
                    url,
                    headers=self.headers,
                    json=data,
                    timeout=60,
                    allow_redirects=True
                )
                
                # è®°å½•HTTPçŠ¶æ€ç 
                logger.info(f"ğŸ“Š HTTP Status Code: {response.status_code}")
                
                # æˆåŠŸå¤„ç†
                if response.status_code in [200, 201]:
                    try:
                        result = response.json()
                        if "commit" in result:
                            commit_url = result["commit"].get("html_url", "")
                            if commit_url:
                                logger.info(f"ğŸ‰ Successfully updated file! Commit URL: {commit_url}")
                                logger.info(f"âœ… Optimistic concurrency control succeeded with SHA: {current_sha[:7]}...")
                            else:
                                logger.info("ğŸ‰ Successfully updated file!")
                            return True
                        else:
                            logger.warning("âš ï¸ No commit information in response, but HTTP status is success")
                            return True
                    except json.JSONDecodeError:
                        logger.error("âŒ Failed to parse JSON response, but HTTP status is success")
                        return True
                
                # é”™è¯¯å¤„ç†
                else:
                    logger.error(f"âŒ Failed to update file, HTTP {response.status_code}")
                    
                    # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
                    try:
                        error_data = response.json()
                        error_message = error_data.get("message", "")
                        logger.error(f"ğŸ’¬ Error message: {error_message}")
                        
                        # å¢å¼ºçš„å†²çªæ£€æµ‹
                        is_conflict = self._is_conflict_error(response, error_message)
                        
                        if is_conflict:
                            conflict_count += 1
                            current_time = time.time()
                            
                            # è®°å½•å†²çªä¿¡æ¯
                            logger.warning(f"âš ï¸ Version conflict detected! This is attempt #{conflict_count} to resolve")
                            logger.warning("ğŸ”„ Will immediately retry with fresh SHA to resolve conflict")
                            
                            # å¦‚æœçŸ­æ—¶é—´å†…å†²çªé¢‘ç¹ï¼Œå¢åŠ ä¸€ä¸ªå°å»¶è¿Ÿé¿å…ç«‹å³é‡è¯•é£æš´
                            if last_conflict_time and (current_time - last_conflict_time) < 2:
                                small_delay = random.uniform(0.5, 1.5)
                                logger.info(f"â±ï¸  Adding small delay ({small_delay:.2f}s) to avoid retry storm")
                                time.sleep(small_delay)
                            
                            last_conflict_time = current_time
                            # ä¸ç­‰å¾…ï¼Œç«‹å³é‡è¯•ä»¥è·å–æœ€æ–°SHA
                            continue
                            
                    except json.JSONDecodeError:
                        logger.debug(f"ğŸ“‹ Response content: {response.text[:200]}...")
                    
                    # å¤„ç†ç‰¹å®šé”™è¯¯
                    if response.status_code == 401:
                        logger.error("ğŸš« Authentication failed, check your GitHub token")
                        logger.error("ğŸ’¡ Tip: Ensure the token has 'contents' write permission")
                        return False
                    elif response.status_code == 403:
                        logger.error("ğŸš« API rate limit or insufficient permissions (403)")
                        if "X-RateLimit-Reset" in response.headers:
                            reset_time = int(response.headers["X-RateLimit-Reset"])
                            wait_time = max(1, reset_time - int(time.time()))
                            logger.info(f"â±ï¸  Rate limit resets in {wait_time} seconds")
                            if attempt < max_retries and wait_time < 30:  # åªåœ¨ç­‰å¾…æ—¶é—´åˆç†æ—¶æ‰ç­‰å¾…
                                logger.info(f"â³ Waiting {wait_time} seconds for rate limit reset")
                                time.sleep(wait_time)
                    elif response.status_code >= 500:
                        logger.error(f"ğŸŒ GitHub server error ({response.status_code})")
                        logger.info("ğŸ’¡ This is likely temporary, will retry with exponential backoff")
                    elif response.status_code == 404:
                        if current_sha:  # å¦‚æœä¹‹å‰èƒ½è·å–åˆ°SHAä½†ç°åœ¨404ï¼Œè¯´æ˜ä»“åº“æˆ–åˆ†æ”¯å¯èƒ½è¢«åˆ é™¤
                            logger.error("âŒ Repository or branch not found")
                            return False
                        else:
                            logger.warning("âš ï¸ File not found, will create new file")
                    else:
                        logger.error(f"â“ Unexpected error code: {response.status_code}")
            
            except requests.RequestException as e:
                logger.error(f"ğŸŒ Request exception while uploading {file_path}: {str(e)}")
                # ç½‘ç»œç›¸å…³é”™è¯¯åº”è¯¥è¿›è¡Œé‡è¯•
                if "Connection refused" in str(e) or "Connection reset" in str(e):
                    logger.info("ğŸ’¡ Network connection error detected, will retry with backoff")
            except Exception as e:
                logger.error(f"â“ Unexpected error while uploading {file_path}: {str(e)}")
                import traceback
                logger.debug(traceback.format_exc())
            
            # æŒ‡æ•°é€€é¿ç­–ç•¥ - å¢å¼ºç‰ˆ
            if attempt < max_retries:
                # è®¡ç®—åŸºç¡€é€€é¿æ—¶é—´
                delay = base_delay * (2 ** (attempt - 1))
                
                # æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é€€é¿æ—¶é—´
                if conflict_count > 0:
                    # å†²çªåœºæ™¯ï¼Œä½¿ç”¨è¾ƒçŸ­ä½†ç¨³å®šçš„é€€é¿
                    delay = min(delay, 10)  # é™åˆ¶æœ€å¤§å»¶è¿Ÿ
                    logger.info(f"ğŸ”„ Conflict scenario detected, using optimized backoff")
                elif "403" in str(locals().get('response', '')):
                    # é€Ÿç‡é™åˆ¶åœºæ™¯ï¼Œä½¿ç”¨è¾ƒé•¿é€€é¿
                    delay = delay * 1.5
                    logger.info(f"â±ï¸  Rate limit scenario detected, using extended backoff")
                elif "500" in str(locals().get('response', '')):
                    # æœåŠ¡å™¨é”™è¯¯åœºæ™¯ï¼Œä½¿ç”¨è¾ƒé•¿é€€é¿
                    delay = delay * 1.2
                    logger.info(f"ğŸŒ Server error scenario detected, using increased backoff")
                
                # æ·»åŠ æ™ºèƒ½éšæœºæŠ–åŠ¨ï¼ˆ5%-25%ï¼‰
                jitter_percent = random.uniform(0.05, 0.25)
                jitter = delay * jitter_percent
                if random.choice([True, False]):
                    delay += jitter
                else:
                    delay = max(1, delay - jitter)
                
                # é™åˆ¶æœ€å¤§å»¶è¿Ÿä¸º60ç§’
                delay = min(delay, 60)
                
                logger.info(f"â±ï¸  Waiting {delay:.2f} seconds before retry (attempt {attempt+1}/{max_retries})...")
                time.sleep(delay)
        
        logger.error(f"âŒ All {max_retries} attempts to upload {file_path} failed")
        logger.error(f"ğŸ’¡ Troubleshooting suggestions:")
        logger.error(f"   1. Check GitHub API permissions and token validity")
        logger.error(f"   2. Verify repository exists and branch is correct")
        logger.error(f"   3. Check if file is being modified by another process concurrently")
        logger.error(f"   4. Increase max_retries or base_delay for more robust retry behavior")
        return False
    
    def _is_conflict_error(self, response, error_message):
        """
        å¢å¼ºçš„å†²çªé”™è¯¯æ£€æµ‹
        
        Args:
            response: HTTPå“åº”å¯¹è±¡
            error_message: é”™è¯¯æ¶ˆæ¯æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦ä¸ºå†²çªé”™è¯¯
        """
        # æ£€æŸ¥HTTPçŠ¶æ€ç 
        if response.status_code == 409:
            return True
            
        # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯ä¸­çš„å…³é”®è¯
        error_lower = error_message.lower()
        conflict_keywords = [
            'sha', 'conflict', 'modified', 'update', 
            'version', 'stale', 'different', 'changed'
        ]
        
        for keyword in conflict_keywords:
            if keyword in error_lower:
                return True
                
        return False

# å‘½ä»¤è¡Œæ¥å£
def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Update files on GitHub using GitHub API with advanced conflict detection',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
        é«˜çº§åŠŸèƒ½è¯´æ˜:
        - ä½¿ç”¨åŸºäºSHAçš„ä¹è§‚å¹¶å‘æ§åˆ¶æœºåˆ¶é¿å…æ›´æ–°å†²çª
        - æ™ºèƒ½æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥ï¼Œé’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹ä¼˜åŒ–å»¶è¿Ÿæ—¶é—´
        - å¢å¼ºçš„å†²çªæ£€æµ‹ç®—æ³•ï¼Œèƒ½å‡†ç¡®è¯†åˆ«å„ç§å†²çªåœºæ™¯
        - è¯¦ç»†çš„æ—¥å¿—è®°å½•å’Œæ•…éšœæ’é™¤å»ºè®®
        - å®Œå…¨é¿å…Git Pushæ“ä½œï¼Œè§£å†³æŒç»­é›†æˆä¸­çš„å†²çªé—®é¢˜
        """)
    
    parser.add_argument('--token', required=True, help='GitHub personal access token')
    parser.add_argument('--owner', required=True, help='Repository owner')
    parser.add_argument('--repo', required=True, help='Repository name')
    parser.add_argument('--file', required=True, help='Path to file to upload')
    parser.add_argument('--branch', default='main', help='Target branch (default: main)')
    parser.add_argument('--message', help='Commit message (optional)')
    parser.add_argument('--dry-run', action='store_true', help='Simulate upload without actual API calls')
    parser.add_argument('--max-retries', type=int, default=5, help='Maximum number of retry attempts (default: 5)')
    parser.add_argument('--base-delay', type=float, default=2, help='Base delay in seconds for exponential backoff (default: 2)')
    
    args = parser.parse_args()
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    logger.info("ğŸš€ GitHub APIæ–‡ä»¶æ›´æ–°å™¨å¯åŠ¨")
    logger.info("ğŸ”„ åŸºäºSHAçš„ä¹è§‚å¹¶å‘æ§åˆ¶å’Œæ™ºèƒ½é‡è¯•ç­–ç•¥")
    logger.info("âœ… å®Œå…¨é¿å…Git Pushå†²çªçš„è§£å†³æ–¹æ¡ˆ")
    
    # æ¨¡æ‹Ÿæ¨¡å¼
    if args.dry_run:
        logger.info("ğŸ§ª Dry run mode enabled - no actual API calls will be made")
        logger.info(f"ğŸ“„ Would upload file: {args.file}")
        logger.info(f"ğŸ“¦ Target repository: {args.owner}/{args.repo}@{args.branch}")
        logger.info(f"ğŸ“ Commit message: {args.message or 'Auto-generated'}")
        logger.info(f"ğŸ”§ Retry configuration: {args.max_retries} retries, {args.base_delay}s base delay")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(args.file):
            logger.error(f"âŒ File {args.file} does not exist")
            return 1
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(args.file)
        logger.info(f"ğŸ“Š File size: {file_size} bytes")
        
        # æµ‹è¯•æ–‡ä»¶ç¼–ç 
        try:
            with open(args.file, 'rb') as f:
                content = f.read(1024)  # åªè¯»å–å‰1KBè¿›è¡Œæµ‹è¯•
            logger.info(f"ğŸ” Successfully read file content sample")
        except Exception as e:
            logger.error(f"âŒ Failed to read file content: {str(e)}")
            return 1
        
        logger.info("âœ… Dry run completed successfully")
        return 0
    
    # å®é™…æ‰§è¡Œ
    try:
        # æ‰“å°è¯¦ç»†é…ç½®ä¿¡æ¯
        logger.info(f"ğŸ“‹ Configuration:")
        logger.info(f"  - Repository: {args.owner}/{args.repo}@{args.branch}")
        logger.info(f"  - File: {args.file}")
        logger.info(f"  - Commit message: {args.message or 'Auto-generated'}")
        logger.info(f"  - Retry strategy: {args.max_retries} retries, {args.base_delay}s base delay")
        
        # åˆ›å»ºæ›´æ–°å™¨å®ä¾‹
            updater = GitHubAPIUpdater(
                token=args.token,
                repo_owner=args.owner,
                repo_name=args.repo,
                branch=args.branch,
                mutual_exclusion=not args.no_mutex,
                workflow_name=args.workflow_name or os.environ.get('GITHUB_WORKFLOW')
            )
        
        # æ‰§è¡Œæ–‡ä»¶æ›´æ–°
        logger.info(f"ğŸ”„ Starting file upload process...")
        start_time = time.time()
        
        success = updater.upload_file(
            file_path=args.file,
            commit_message=args.message,
            max_retries=args.max_retries,
            base_delay=args.base_delay
        )
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        logger.info(f"â±ï¸  Execution time: {execution_time:.2f} seconds")
        
        # è¿”å›ç»“æœ
        if success:
            logger.info("ğŸ‰ GitHub APIæ–‡ä»¶æ›´æ–°æˆåŠŸå®Œæˆï¼")
            logger.info("âœ… åŸºäºSHAçš„ä¹è§‚å¹¶å‘æ§åˆ¶æœºåˆ¶æˆåŠŸé¿å…äº†å†²çª")
            logger.info("ğŸ¯ ä»»åŠ¡å®Œæˆï¼Œé€€å‡ºçŠ¶æ€ç : 0")
            return 0
        else:
            logger.error("âŒ GitHub APIæ–‡ä»¶æ›´æ–°å¤±è´¥ï¼")
            logger.error("ğŸ’¡ æ•…éšœæ’é™¤å»ºè®®:")
            logger.error("  1. æ£€æŸ¥GitHub APIæƒé™å’Œtokenæœ‰æ•ˆæ€§")
            logger.error("  2. éªŒè¯ä»“åº“å­˜åœ¨ä¸”åˆ†æ”¯æ­£ç¡®")
            logger.error("  3. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹æ­£åœ¨ä¿®æ”¹åŒä¸€æ–‡ä»¶")
            logger.error("  4. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒGitHub APIçŠ¶æ€")
            logger.error("  5. å°è¯•å¢åŠ --max-retriesæˆ–--base-delayå‚æ•°å€¼")
            logger.error("ğŸ¯ ä»»åŠ¡å¤±è´¥ï¼Œé€€å‡ºçŠ¶æ€ç : 1")
            return 1
            
    except ValueError as e:
        logger.error(f"âŒ å‚æ•°éªŒè¯é”™è¯¯: {str(e)}")
        return 2
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {str(e)}")
        import traceback
        logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
