#!/usr/bin/env python3
"""
å·¥ä½œæµäº’æ–¥é”è„šæœ¬ - é˜²æ­¢å¤šä¸ªå·¥ä½œæµåŒæ—¶æ‰§è¡Œ

æ­¤è„šæœ¬é€šè¿‡GitHub Actions APIæ£€æŸ¥æŒ‡å®šå·¥ä½œæµçš„è¿è¡ŒçŠ¶æ€ï¼Œå¹¶å®ç°äº’æ–¥é”æœºåˆ¶ï¼Œç¡®ä¿åœ¨ä»»æ„æ—¶åˆ»
åªæœ‰ä¸€ä¸ªå·¥ä½œæµå®ä¾‹åœ¨è¿è¡Œï¼Œä»è€Œé¿å…Gitæ¨é€å†²çªå’Œ'fetch first'é”™è¯¯ã€‚

ä½¿ç”¨æ–¹æ³•:
  python workflow_mutex.py --owner <owner> --repo <repo> --workflow <workflow_name> --token <github_token> [--timeout <seconds>] [--wait]
"""

import os
import sys
import time
import argparse
import requests
import logging
import uuid
from datetime import datetime, timedelta

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('workflow_mutex.log')
    ]
)
logger = logging.getLogger('workflow_mutex')

class WorkflowMutex:
    """
    å·¥ä½œæµäº’æ–¥é”ç®¡ç†å™¨ï¼Œä½¿ç”¨GitHub Actions APIç®¡ç†å·¥ä½œæµè¿è¡Œ
    """
    
    def __init__(self, owner, repo, workflow_name, token, timeout=300):
        self.owner = owner
        self.repo = repo
        self.workflow_name = workflow_name
        self.token = token
        self.timeout = timeout
        self.api_base_url = f"https://api.github.com/repos/{owner}/{repo}"
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'GitHub-Workflow-Mutex'
        }
        self.run_id = os.environ.get('GITHUB_RUN_ID', f'manual-{uuid.uuid4()}')
        
    def get_workflow_id(self):
        """
        è·å–å·¥ä½œæµID
        """
        try:
            url = f"{self.api_base_url}/actions/workflows"
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            workflows = response.json().get('workflows', [])
            for workflow in workflows:
                if workflow['name'] == self.workflow_name:
                    logger.info(f"æ‰¾åˆ°å·¥ä½œæµ '{self.workflow_name}'ï¼ŒID: {workflow['id']}")
                    return workflow['id']
            
            logger.error(f"æœªæ‰¾åˆ°å·¥ä½œæµ: {self.workflow_name}")
            return None
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµIDå¤±è´¥: {str(e)}")
            return None
    
    def get_running_workflows(self, workflow_id):
        """
        è·å–æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹
        """
        try:
            url = f"{self.api_base_url}/actions/workflows/{workflow_id}/runs?status=in_progress"
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            runs = response.json().get('workflow_runs', [])
            # è¿‡æ»¤æ‰å½“å‰è¿è¡Œå®ä¾‹å’Œå·²è¶…æ—¶çš„è¿è¡Œ
            current_time = datetime.now().timestamp()
            running_runs = []
            
            for run in runs:
                # è·³è¿‡å½“å‰è¿è¡Œå®ä¾‹
                if str(run['id']) == str(self.run_id):
                    continue
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼ˆè¶…è¿‡æŒ‡å®šç§’æ•°ä»åœ¨è¿è¡Œï¼‰
                created_at = datetime.strptime(run['created_at'], '%Y-%m-%dT%H:%M:%SZ').timestamp()
                if current_time - created_at > self.timeout:
                    logger.warning(f"æ£€æµ‹åˆ°è¶…æ—¶è¿è¡Œ: {run['id']} (åˆ›å»ºäº {run['created_at']})")
                    continue
                
                running_runs.append(run)
            
            return running_runs
        except Exception as e:
            logger.error(f"è·å–è¿è¡Œä¸­å·¥ä½œæµå¤±è´¥: {str(e)}")
            return []
    
    def get_other_workflow_runs(self):
        """
        è·å–æ‰€æœ‰å¯èƒ½å†²çªçš„å…¶ä»–å·¥ä½œæµè¿è¡Œ
        è¿™é‡Œå‡è®¾å¯èƒ½æœ‰å…¶ä»–å·¥ä½œæµä¹Ÿåœ¨æ“ä½œç›¸åŒçš„æ–‡ä»¶
        """
        try:
            # è·å–æ‰€æœ‰å·¥ä½œæµåç§°ï¼ˆç”¨äºå†²çªæ£€æµ‹ï¼‰
            workflow_names_to_check = ['TVZY Daily Update', 'TVZY Daily Update API']
            
            conflicting_runs = []
            
            for wf_name in workflow_names_to_check:
                if wf_name == self.workflow_name:
                    continue
                    
                wf_id = self._get_workflow_id_by_name(wf_name)
                if wf_id:
                    url = f"{self.api_base_url}/actions/workflows/{wf_id}/runs?status=in_progress"
                    response = requests.get(url, headers=self.headers)
                    response.raise_for_status()
                    
                    runs = response.json().get('workflow_runs', [])
                    conflicting_runs.extend(runs)
            
            return conflicting_runs
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†²çªå·¥ä½œæµå¤±è´¥: {str(e)}")
            return []
    
    def _get_workflow_id_by_name(self, workflow_name):
        """
        è¾…åŠ©æ–¹æ³•ï¼šé€šè¿‡åç§°è·å–å·¥ä½œæµID
        """
        try:
            url = f"{self.api_base_url}/actions/workflows"
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            workflows = response.json().get('workflows', [])
            for workflow in workflows:
                if workflow['name'] == workflow_name:
                    return workflow['id']
            
            return None
        except Exception:
            return None
    
    def acquire_lock(self, wait=False, max_wait_time=300):
        """
        è·å–äº’æ–¥é”
        
        Args:
            wait: æ˜¯å¦ç­‰å¾…å…¶ä»–å·¥ä½œæµå®Œæˆ
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸè·å–é”
        """
        start_time = time.time()
        
        while True:
            # è·å–å·¥ä½œæµID
            workflow_id = self.get_workflow_id()
            if not workflow_id:
                logger.error("æ— æ³•è·å–å·¥ä½œæµIDï¼Œæ— æ³•ç»§ç»­äº’æ–¥æ£€æŸ¥")
                return False
            
            # æ£€æŸ¥åŒå·¥ä½œæµçš„å…¶ä»–è¿è¡Œå®ä¾‹
            running_instances = self.get_running_workflows(workflow_id)
            
            # æ£€æŸ¥å…¶ä»–å¯èƒ½å†²çªçš„å·¥ä½œæµ
            conflicting_runs = self.get_other_workflow_runs()
            
            # åˆå¹¶æ‰€æœ‰å†²çªçš„è¿è¡Œ
            all_conflicts = running_instances + conflicting_runs
            
            if not all_conflicts:
                # æ²¡æœ‰å†²çªï¼ŒæˆåŠŸè·å–é”
                logger.info(f"âœ… æˆåŠŸè·å–å·¥ä½œæµäº’æ–¥é”: {self.workflow_name}")
                self._write_lock_info()
                return True
            
            # æœ‰å†²çª
            conflict_count = len(all_conflicts)
            logger.warning(f"âš ï¸  æ£€æµ‹åˆ° {conflict_count} ä¸ªå†²çªçš„å·¥ä½œæµè¿è¡Œ")
            
            for run in all_conflicts:
                run_name = run.get('name', 'Unknown Workflow')
                run_id = run.get('id', 'Unknown ID')
                run_status = run.get('status', 'Unknown Status')
                run_created = run.get('created_at', 'Unknown Time')
                logger.warning(f"  - å·¥ä½œæµ: {run_name} (ID: {run_id}, çŠ¶æ€: {run_status}, åˆ›å»ºäº: {run_created})")
            
            # æ£€æŸ¥æ˜¯å¦ç­‰å¾…
            if not wait:
                logger.error("âŒ æ£€æµ‹åˆ°å†²çªå·¥ä½œæµï¼Œæœªé…ç½®ç­‰å¾…ï¼Œäº’æ–¥é”è·å–å¤±è´¥")
                return False
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§ç­‰å¾…æ—¶é—´
            if time.time() - start_time > max_wait_time:
                logger.error(f"âŒ ç­‰å¾…äº’æ–¥é”è¶…æ—¶ ({max_wait_time}ç§’)")
                return False
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
            wait_time = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            logger.info(f"ğŸ”„ ç­‰å¾… {wait_time} ç§’åé‡è¯•äº’æ–¥é”æ£€æŸ¥...")
            time.sleep(wait_time)
    
    def _write_lock_info(self):
        """
        å†™å…¥é”ä¿¡æ¯åˆ°æ–‡ä»¶ï¼Œç”¨äºè°ƒè¯•å’Œè·Ÿè¸ª
        """
        try:
            lock_info = {
                'workflow_name': self.workflow_name,
                'run_id': self.run_id,
                'acquired_at': datetime.now().isoformat(),
                'owner': self.owner,
                'repo': self.repo
            }
            
            with open('workflow_lock_info.json', 'w', encoding='utf-8') as f:
                import json
                json.dump(lock_info, f, indent=2, ensure_ascii=False)
                
            logger.info("äº’æ–¥é”ä¿¡æ¯å·²ä¿å­˜åˆ° workflow_lock_info.json")
        except Exception as e:
            logger.warning(f"ä¿å­˜é”ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def check_and_wait(self, interval=5, max_attempts=10):
        """
        æ£€æŸ¥å¹¶ç­‰å¾…å…¶ä»–å·¥ä½œæµå®Œæˆï¼Œè¿”å›æ˜¯å¦æˆåŠŸ
        """
        logger.info(f"å¼€å§‹æ£€æŸ¥å¹¶ç­‰å¾…å¯èƒ½çš„å†²çªå·¥ä½œæµ...")
        
        for attempt in range(max_attempts):
            if self.acquire_lock(wait=False):
                return True
                
            logger.info(f"å°è¯• {attempt + 1}/{max_attempts}: å†²çªå·¥ä½œæµä»åœ¨è¿è¡Œï¼Œç­‰å¾… {interval} ç§’...")
            time.sleep(interval)
        
        logger.error(f"å·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•° ({max_attempts})ï¼Œå†²çªå·¥ä½œæµä»åœ¨è¿è¡Œ")
        return False
    
    def use_fallback_strategy(self):
        """
        ä½¿ç”¨å¤‡é€‰ç­–ç•¥ï¼šé€šè¿‡GitHub APIç›´æ¥æ›´æ–°æ–‡ä»¶ï¼Œé¿å…Gitå†²çª
        """
        logger.info("å¯ç”¨å¤‡é€‰ç­–ç•¥ï¼šä½¿ç”¨GitHub APIè¿›è¡Œæ–‡ä»¶æ›´æ–°")
        
        # åˆ›å»ºæ ‡è®°æ–‡ä»¶ï¼Œè¡¨ç¤ºä½¿ç”¨äº†å¤‡é€‰ç­–ç•¥
        try:
            with open('used_api_fallback.txt', 'w') as f:
                f.write(f"API fallback used at: {datetime.now().isoformat()}\n")
                f.write(f"Workflow: {self.workflow_name}\n")
                f.write(f"Run ID: {self.run_id}\n")
            
            logger.info("å·²åˆ›å»ºAPIå¤‡é€‰ç­–ç•¥æ ‡è®°æ–‡ä»¶")
            return True
        except Exception as e:
            logger.error(f"åˆ›å»ºAPIå¤‡é€‰ç­–ç•¥æ ‡è®°å¤±è´¥: {str(e)}")
            return False

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='GitHub Actionså·¥ä½œæµäº’æ–¥é”')
    parser.add_argument('--owner', required=True, help='GitHubä»“åº“æ‰€æœ‰è€…')
    parser.add_argument('--repo', required=True, help='GitHubä»“åº“åç§°')
    parser.add_argument('--workflow', required=True, help='å·¥ä½œæµåç§°')
    parser.add_argument('--token', required=True, help='GitHubè®¿é—®ä»¤ç‰Œ')
    parser.add_argument('--timeout', type=int, default=300, help='å·¥ä½œæµè¿è¡Œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--wait', action='store_true', help='æ˜¯å¦ç­‰å¾…å…¶ä»–å·¥ä½œæµå®Œæˆ')
    parser.add_argument('--max-wait', type=int, default=300, help='æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--fallback', action='store_true', help='åœ¨æ— æ³•è·å–é”æ—¶ä½¿ç”¨å¤‡é€‰ç­–ç•¥')
    
    return parser.parse_args()

def main():
    """
    ä¸»å‡½æ•°
    """
    try:
        args = parse_args()
        
        # åˆ›å»ºäº’æ–¥é”ç®¡ç†å™¨
        mutex = WorkflowMutex(
            owner=args.owner,
            repo=args.repo,
            workflow_name=args.workflow,
            token=args.token,
            timeout=args.timeout
        )
        
        logger.info(f"å¼€å§‹å·¥ä½œæµäº’æ–¥æ£€æŸ¥: {args.workflow}")
        
        # å°è¯•è·å–é”
        if mutex.acquire_lock(wait=args.wait, max_wait_time=args.max_wait):
            logger.info("äº’æ–¥é”è·å–æˆåŠŸï¼Œå·¥ä½œæµå¯ä»¥ç»§ç»­æ‰§è¡Œ")
            # è¾“å‡ºæˆåŠŸä¿¡æ¯ï¼Œä¾›CIç¯å¢ƒä½¿ç”¨
            print("::set-output name=mutex_acquired::true")
            print("MUTEX_ACQUIRED=true")
            return 0
        else:
            # é”è·å–å¤±è´¥
            logger.error("æ— æ³•è·å–äº’æ–¥é”")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¤‡é€‰ç­–ç•¥
            if args.fallback:
                if mutex.use_fallback_strategy():
                    logger.warning("å·²å¯ç”¨å¤‡é€‰APIæ›´æ–°ç­–ç•¥")
                    print("::set-output name=mutex_fallback_used::true")
                    print("MUTEX_FALLBACK_USED=true")
                    return 0
                else:
                    logger.error("å¤‡é€‰ç­–ç•¥ä¹Ÿå¤±è´¥")
            
            # è¾“å‡ºå¤±è´¥ä¿¡æ¯
            print("::set-output name=mutex_acquired::false")
            print("MUTEX_ACQUIRED=false")
            return 1
            
    except Exception as e:
        logger.error(f"å·¥ä½œæµäº’æ–¥æ£€æŸ¥å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
