#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ’­æºæœ‰æ•ˆæ€§éªŒè¯å·¥å…·
åŠŸèƒ½ï¼šéªŒè¯M3Uå’ŒTXTæ ¼å¼ç›´æ’­æºæ–‡ä»¶ä¸­çš„URLæœ‰æ•ˆæ€§ï¼Œæ£€æµ‹è§†é¢‘åˆ†è¾¨ç‡ï¼Œå¹¶ç”Ÿæˆæ–°çš„ç›´æ’­æºæ–‡ä»¶
å‚è€ƒBlackBird-Playerçš„éªŒè¯æ€è·¯è¿›è¡Œä¼˜åŒ–
"""

import os
import re
import json
import time
import subprocess
import concurrent.futures
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import tempfile
import multiprocessing
from urllib.parse import urlparse
from datetime import datetime

# éªŒè¯æ—¶é—´æˆ³è·Ÿè¸ªå™¨ - å‚è€ƒBlackBird-Playerçš„result.txtæ ¼å¼
class ValidationTimestamp:
    """éªŒè¯æ—¶é—´æˆ³è·Ÿè¸ªå™¨ - å‚è€ƒBlackBird-Playerçš„æ›´æ–°æ—¶é—´è®°å½•æ–¹å¼"""
    
    _instance = None
    _timestamp = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return cls._instance
    
    @classmethod
    def get_timestamp(cls):
        """è·å–å½“å‰éªŒè¯æ—¶é—´æˆ³"""
        return cls._timestamp
    
    @classmethod
    def update_timestamp(cls):
        """æ›´æ–°éªŒè¯æ—¶é—´æˆ³"""
        cls._timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return cls._timestamp
    
    @classmethod
    def reset(cls):
        """é‡ç½®æ—¶é—´æˆ³"""
        cls._timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def _get_resolution_from_hls(url, timeout, headers=None):
    """ä»HLSæ’­æ”¾åˆ—è¡¨ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
    import re
    import requests
    try:
        session = requests.Session()
        response = session.get(url, timeout=min(timeout, 3), headers=headers, allow_redirects=True)
        if response.status_code != 200:
            return None

        content = response.text
        re_resolution = re.compile(r'#EXT-X-STREAM-INF.*?RESOLUTION=(\d+)x(\d+)', re.IGNORECASE | re.DOTALL)
        matches = re_resolution.findall(content)

        if matches:
            max_height = 0
            best_width = 0
            for width, height in matches:
                h = int(height)
                w = int(width)
                if h > max_height and h > 0 and w > 0:
                    max_height = h
                    best_width = w
            if max_height > 0:
                return f"{best_width}*{max_height}", 'hls', {'source': 'hls_playlist'}
            return None, None, {}
        return None, None, {}
    except Exception:
        return None


def _extract_first_segment_from_m3u8(m3u8_url, timeout, headers=None):
    """ä»m3u8æ’­æ”¾åˆ—è¡¨ä¸­æå–ç¬¬ä¸€ä¸ªåª’ä½“ç‰‡æ®µURL - ä¼˜åŒ–ç‰ˆæœ¬"""
    import re
    import requests
    from urllib.parse import urljoin, urlparse
    try:
        session = requests.Session()
        response = session.get(m3u8_url, timeout=min(timeout, 3), headers=headers, allow_redirects=True)
        if response.status_code != 200:
            return None

        content = response.text
        lines = content.splitlines()
        
        base_url = m3u8_url
        parsed_url = urlparse(m3u8_url)
        if parsed_url.path.rstrip('/'):
            base_url = m3u8_url.rsplit('/', 1)[0] + '/'

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            if line.startswith('http://') or line.startswith('https://'):
                return line
            elif line.startswith('/'):
                return urljoin(f"{parsed_url.scheme}://{parsed_url.netloc}", line)
            else:
                return urljoin(base_url, line)

        return None
    except Exception:
        return None


def _get_resolution_from_segment(segment_url, timeout, headers=None):
    """ä½¿ç”¨ffprobeè·å–åª’ä½“ç‰‡æ®µçš„åˆ†è¾¨ç‡ - ä¼˜åŒ–ç‰ˆæœ¬"""
    import subprocess
    import json
    try:
        if not segment_url:
            return None

        cmd = [
            'ffprobe', '-v', 'error', '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height', '-of', 'json',
            '-timeout', str(int(timeout * 1000000))
        ]

        if headers:
            cmd.extend([
                '-headers', f'Referer: {headers.get("Referer", "")}\r\nUser-Agent: {headers.get("User-Agent", "Mozilla/5.0")}\r\n'
            ])

        cmd.append(segment_url)

        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )

        if result.returncode == 0:
            try:
                data = json.loads(result.stdout)
                if 'streams' in data and len(data['streams']) > 0:
                    width = data['streams'][0].get('width', 0)
                    height = data['streams'][0].get('height', 0)
                    if width and height and width > 0 and height > 0:
                        codec = data['streams'][0].get('codec_name', 'æœªçŸ¥')
                        return f"{width}*{height}", codec, {'source': 'segment'}
            except json.JSONDecodeError:
                pass

        return None, None, {}
    except Exception:
        return None


def _ffprobe_get_resolution(url, timeout, headers=None, retry=1):
    """åœ¨è¿›ç¨‹æ± ä¸­æ‰§è¡Œçš„ffprobeåˆ†è¾¨ç‡æ£€æµ‹å‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆå‚è€ƒæ–°å¯¹è¯.txtï¼‰"""
    import subprocess
    import json

    url_lower = url.lower()
    is_rtsp = url_lower.startswith('rtsp://')
    is_hls = url_lower.endswith(('.m3u8', '.m3u')) or '/hls/' in url_lower or '/live/' in url_lower
    is_udp = url_lower.startswith('udp://') or url_lower.startswith('rtp://')

    timeout_us = int(timeout * 1000000)
    skip_bytes = 500000

    for attempt in range(retry + 1):
        try:
            cmd = [
                'ffprobe', '-v', 'error',
                '-timeout', str(timeout_us),
                '-skip_initial_bytes', str(skip_bytes),
                '-flags', 'low_delay',
                '-fflags', '+genpts',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=width,height,codec_name:format=probe_score,duration',
                '-of', 'json'
            ]

            if is_rtsp:
                cmd.extend(['-rtsp_transport', 'tcp'])
            if is_hls:
                cmd.extend(['-allowed_extensions', 'ALL'])
            if is_udp:
                cmd.extend(['-f', 'mpegts'])

            if headers:
                cmd.extend([
                    '-headers', f'Referer: {headers.get("Referer", "")}\r\nUser-Agent: {headers.get("User-Agent", "Mozilla/5.0")}\r\n'
                ])

            cmd.append(url)

            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=timeout,
                shell=False, encoding='utf-8', errors='ignore',
                creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
            )

            if result.returncode == 0:
                try:
                    data = json.loads(result.stdout)
                    format_info = data.get('format', {})
                    probe_score = format_info.get('probe_score', 0)
                    format_duration = format_info.get('duration', 'unknown')

                    if probe_score <= 0:
                        if attempt < retry:
                            continue
                        return None, None, {'error': 'format_unrecognizable', 'probe_score': probe_score}

                    if 'streams' in data and len(data['streams']) > 0:
                        stream = data['streams'][0]
                        width = stream.get('width', 0)
                        height = stream.get('height', 0)
                        if width and height and width > 0 and height > 0:
                            codec = stream.get('codec_name', 'æœªçŸ¥')
                            return f"{width}*{height}", codec, {
                                'probe_score': probe_score,
                                'duration': format_duration,
                                'codec': codec
                            }
                except json.JSONDecodeError:
                    pass

            if attempt < retry:
                continue

            return None, None, {'error': 'probe_failed', 'returncode': result.returncode}

        except subprocess.TimeoutExpired:
            if attempt < retry:
                continue
            return None, None, {'error': 'timeout'}

        except Exception as e:
            if attempt < retry:
                continue
            return None, None, {'error': str(e)}

    return None, None, {'error': 'max_retries_exceeded'}


def _test_stream_playback(url, timeout, headers=None):
    """BlackBird-Playeré£æ ¼çš„è¯•æ’­éªŒè¯å‡½æ•° - é€šè¿‡å®é™…æ’­æ”¾æµ‹è¯•åˆ¤æ–­URLæ˜¯å¦çœŸæ­£æœ‰æ•ˆ
    å¹¶è·å–çœŸå®åˆ†è¾¨ç‡ï¼Œè€Œä¸æ˜¯ä»URLæ¨¡å¼æ¨æ–­
    
    è¯•æ’­ç­–ç•¥ï¼š
    1. UDP/RTSP/RTMP/RTP: ä½¿ç”¨FFmpegå°è¯•è§£ç ä¸€å°æ®µæ•°æ®ï¼Œç¡®è®¤æµå¯æ’­æ”¾
    2. IPv6: ä½¿ç”¨FFprobeæ¢æµ‹ï¼Œæ£€æŸ¥æ˜¯å¦èƒ½åœ¨IPv6ç¯å¢ƒä¸‹æ­£å¸¸è¿æ¥
    3. æˆåŠŸæ’­æ”¾åè·å–çœŸå®åˆ†è¾¨ç‡å’Œç¼–ç ä¿¡æ¯
    """
    import subprocess
    import json
    import socket
    import threading
    import time
    
    url_lower = url.lower()
    is_ipv6 = '[' in url and ']' in url
    is_udp = url_lower.startswith('udp://') or url_lower.startswith('rtp://')
    is_rtsp = url_lower.startswith('rtsp://')
    is_rtmp = url_lower.startswith('rtmp://')
    
    timeout_us = int(timeout * 1000000)
    
    def _check_socket_connection(host, port, timeout_sec=2):
        """æ£€æŸ¥socketè¿æ¥æ˜¯å¦å¯è¾¾"""
        try:
            sock = socket.socket(socket.AF_INET6 if ':' in host else socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout_sec)
            sock.connect((host, int(port)))
            sock.close()
            return True
        except Exception:
            return False
    
    def _try_udp_multicast(url, timeout_sec):
        """å°è¯•UDPç»„æ’­è¿æ¥æ£€æŸ¥"""
        try:
            if not url.startswith('udp://'):
                return False
            parts = url[7:].split('@')
            if len(parts) < 2:
                return False
            addr_port = parts[1].split('/')[0]
            addr, port = addr_port.rsplit(':', 1)
            return _check_socket_connection(addr, int(port), timeout_sec)
        except Exception:
            return False
    
    try:
        if is_udp:
            if not _try_udp_multicast(url, min(timeout, 3)):
                return None, None, {'error': 'udp_unreachable', 'method': 'socket_check'}
        
        elif is_rtsp or is_rtmp:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            port = parsed.port or (554 if is_rtsp else 1935)
            if not _check_socket_connection(parsed.hostname, port, min(timeout, 3)):
                return None, None, {'error': f'{("RTSP" if is_rtsp else "RTMP")}_unreachable', 'method': 'socket_check'}
        
        cmd = [
            'ffprobe', '-v', 'error',
            '-timeout', str(timeout_us),
            '-skip_initial_bytes', '0',
            '-flags', 'low_delay',
            '-fflags', '+genpts+discardcorrupt',
            '-max_delay', '500000',
            '-reorder_queue_size', '2048',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height,codec_name,duration,bit_rate:format=duration,format_name',
            '-of', 'json'
        ]
        
        if is_rtsp:
            cmd.extend(['-rtsp_transport', 'tcp'])
        elif is_rtmp:
            cmd.extend(['-f', 'flv'])
        elif is_udp:
            cmd.extend(['-f', 'mpegts', '-err_detect', 'ignore_err'])
        elif is_ipv6:
            cmd.extend(['-timeout', str(timeout_us)])
        
        if headers:
            cmd.extend([
                '-headers', f'Referer: {headers.get("Referer", "")}\r\nUser-Agent: {headers.get("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")}\r\n'
            ])
        
        cmd.append(url)
        
        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout + 2,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )
        
        if result.returncode == 0:
            try:
                data = json.loads(result.stdout)
                format_info = data.get('format', {})
                format_duration = format_info.get('duration', '0')
                format_name = format_info.get('format_name', 'unknown')
                
                if 'streams' in data and len(data['streams']) > 0:
                    stream = data['streams'][0]
                    width = stream.get('width', 0)
                    height = stream.get('height', 0)
                    
                    if width and height and width > 0 and height > 0:
                        codec = stream.get('codec_name', 'æœªçŸ¥')
                        bitrate = stream.get('bit_rate', None)
                        
                        return f"{width}*{height}", codec, {
                            'method': 'playback_test',
                            'verified': True,
                            'duration': format_duration,
                            'format': format_name,
                            'bitrate': bitrate,
                            'protocol': 'ipv6' if is_ipv6 else ('rtsp' if is_rtsp else ('rtmp' if is_rtmp else ('udp' if is_udp else 'rtp')))
                        }
                
                return None, None, {'error': 'no_video_stream', 'format': format_name}
                
            except json.JSONDecodeError:
                return None, None, {'error': 'parse_failed'}
        
        error_output = result.stderr.lower() if result.stderr else ''
        
        if 'connection refused' in error_output or 'no such file' in error_output:
            return None, None, {'error': 'connection_refused'}
        elif 'network is unreachable' in error_output or 'address' in error_output:
            return None, None, {'error': 'network_unreachable'}
        elif 'timeout' in error_output:
            return None, None, {'error': 'timeout'}
        else:
            return None, None, {'error': 'probe_failed', 'stderr': result.stderr[:200] if result.stderr else 'unknown'}
            
    except subprocess.TimeoutExpired:
        return None, None, {'error': 'timeout'}
    except Exception as e:
        return None, None, {'error': str(e)}


def _ffprobe_get_audio_info(url, timeout, headers=None):
    """ä½¿ç”¨ffprobeè·å–éŸ³é¢‘æµä¿¡æ¯ï¼ˆç¼–ç æ ¼å¼ã€é‡‡æ ·ç‡ã€å£°é“æ•°ã€ç ç‡ç­‰ï¼‰"""
    import subprocess
    import json
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'a:0',
            '-show_entries', 'stream=codec_name,sample_rate,channels,bit_rate',
            '-of', 'json'
        ]

        if headers:
            cmd.extend([
                '-headers', f'Referer: {headers.get("Referer", "")}\r\nUser-Agent: {headers.get("User-Agent", "Mozilla/5.0")}\r\n'
            ])

        cmd.append(url)

        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )

        if result.returncode != 0:
            return None

        output = json.loads(result.stdout)
        if 'streams' in output and len(output['streams']) > 0:
            stream = output['streams'][0]
            return {
                'codec': stream.get('codec_name', 'æœªçŸ¥'),
                'sample_rate': stream.get('sample_rate', 'æœªçŸ¥'),
                'channels': stream.get('channels', 'æœªçŸ¥'),
                'bit_rate': stream.get('bit_rate', 'æœªçŸ¥')
            }
        return None
    except Exception:
        return None


def _check_url_has_audio(url, timeout, headers=None):
    """æ£€æŸ¥URLæ˜¯å¦æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æµï¼Œè¿”å›å¸ƒå°”å€¼"""
    import subprocess
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'a:0',
            '-show_entries', 'stream=codec_name',
            '-of', 'csv=p=0'
        ]

        if headers:
            cmd.extend([
                '-headers', f'Referer: {headers.get("Referer", "")}\r\nUser-Agent: {headers.get("User-Agent", "Mozilla/5.0")}\r\n'
            ])

        cmd.append(url)

        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )

        return result.returncode == 0 and result.stdout.strip()
    except Exception:
        return False


def _check_mediainfo_available():
    """æ£€æŸ¥MediaInfoå‘½ä»¤è¡Œå·¥å…·æ˜¯å¦å¯ç”¨"""
    import subprocess
    try:
        result = subprocess.run(
            ['mediainfo', '--version'],
            capture_output=True, text=True, timeout=5,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )
        return result.returncode == 0
    except Exception:
        return False


def _mediainfo_get_resolution(url, timeout, headers=None):
    """ä½¿ç”¨MediaInfoè·å–è§†é¢‘åˆ†è¾¨ç‡ï¼Œä½œä¸ºffprobeçš„å¤‡é€‰æ–¹æ¡ˆ"""
    import subprocess
    import re

    def _parse_mediainfo_output(output):
        """è§£æMediaInfoè¾“å‡ºï¼Œæå–åˆ†è¾¨ç‡"""
        try:
            lines = output.strip().split('\n')
            for line in lines:
                line = line.strip()
                if 'x' in line:
                    parts = line.split('x')
                    if len(parts) == 2:
                        width = parts[0].strip()
                        height = parts[1].strip()
                        if width.isdigit() and height.isdigit():
                            w, h = int(width), int(height)
                            if w > 0 and h > 0:
                                return f"{w}*{h}"
            return None
        except Exception:
            return None

    try:
        cmd = [
            'mediainfo', '--Output=Video;%Width%x%Height%', url
        ]

        if headers:
            env = os.environ.copy()
            env['HTTP_REFERER'] = headers.get('Referer', '')
            env['HTTP_USER_AGENT'] = headers.get('User-Agent', 'Mozilla/5.0')
        else:
            env = None

        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout,
            shell=False, encoding='utf-8', errors='ignore',
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0,
            env=env
        )

        if result.returncode != 0:
            return None

        return _parse_mediainfo_output(result.stdout)

    except subprocess.TimeoutExpired:
        return None
    except Exception:
        return None


class IPTVValidator:
    def __init__(self, input_file, output_file=None, max_workers=None, timeout=5, debug=False, original_filename=None, skip_resolution=False, filter_no_audio=False):
        self.input_file = input_file
        self.original_filename = original_filename
        self.max_workers = max_workers or min(30, multiprocessing.cpu_count() * 4)
        self.debug = debug
        self.channels = []
        self.categories = []
        self.batch_size = min(max(self.max_workers * 4, 50), 200)
        self.stop_requested = False
        self.processed_external_urls = set()
        self._active_futures = set()
        self.all_results = []
        self.timeouts = {
            'http_head': min(timeout, 5),
            'http_get': timeout,
            'non_http': min(timeout * 2, 10),
            'ffprobe': min(timeout * 2.5, 12)
        }
        self.skip_resolution = skip_resolution
        self.filter_no_audio = filter_no_audio
        
        # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼Œå‡å°‘é‡å¤ç¼–è¯‘å¼€é”€
        self._compile_regex_patterns()
        
        # åˆå§‹åŒ–HTTPä¼šè¯å’Œè¿æ¥æ± 
        self.session = self._init_http_session()

        # æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼ˆå¿…é¡»åœ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åä¹‹å‰ï¼‰
        self.file_type = self._detect_file_type()

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆä¾èµ–äºfile_typeï¼‰
        self.output_file = output_file or self._generate_output_filename()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self._check_output_dir()
        self.ffprobe_available = self._check_ffprobe_availability()
        self.mediainfo_available = _check_mediainfo_available()
        if self.debug:
            if self.mediainfo_available:
                print("[è°ƒè¯•] MediaInfoå¯ç”¨ï¼Œå°†ä½œä¸ºffprobeçš„å¤‡é€‰æ–¹æ¡ˆ")
            else:
                print("[è°ƒè¯•] MediaInfoä¸å¯ç”¨ï¼Œä»…ä½¿ç”¨ffprobe")
        
        # åˆå§‹åŒ–ffprobeè¿›ç¨‹æ± 
        self.ffprobe_pool = None
        self._validation_pool = None  # ç”¨äºéªŒè¯çš„çº¿ç¨‹æ± 
        if self.ffprobe_available and not self.skip_resolution:
            # ä½¿ç”¨ThreadPoolExecutoré¿å…ProcessPoolExecutorçš„å¤šè¿›ç¨‹å¯åŠ¨é—®é¢˜
            self.ffprobe_pool = concurrent.futures.ThreadPoolExecutor(max_workers=multiprocessing.cpu_count())
            
    def _compile_regex_patterns(self):
        """é¢„ç¼–è¯‘æ‰€æœ‰ä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œå‡å°‘é‡å¤ç¼–è¯‘å¼€é”€"""
        # M3Uæ–‡ä»¶è§£ææ­£åˆ™è¡¨è¾¾å¼
        self.re_extinf_name = re.compile(r'#EXTINF:.*,(.+)')
        self.re_tvg_name = re.compile(r'tvg-name="([^"]+)"')
        self.re_group_title = re.compile(r'group-title="([^"]+)"')
        
        # åˆ†è¾¨ç‡æå–æ­£åˆ™è¡¨è¾¾å¼
        self.re_resolution = re.compile(r'\[(\d+\*\d+)\]')
        
        # URLå‚æ•°ä¸­çš„åˆ†è¾¨ç‡æå–æ­£åˆ™è¡¨è¾¾å¼
        # æ”¯æŒæ ¼å¼ï¼š$3840x2160, ?resolution=1920x1080, &res=720, resolution=1280*720
        self.re_url_resolution_dollar = re.compile(r'\$(\d+)x(\d+)')
        self.re_url_resolution_param = re.compile(r'[?&]resolution=(\d+)[x*](\d+)', re.IGNORECASE)
        self.re_url_res_param = re.compile(r'[?&]res=(\d+)', re.IGNORECASE)
        
        # TXTæ–‡ä»¶åˆ†ç±»è§£ææ­£åˆ™è¡¨è¾¾å¼ - æ”¯æŒé€—å·æˆ–Tabåˆ†éš”
        self.re_category = re.compile(r'^(.+?)[\t,]\s*#genre#$')
        
        # URLåè®®æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼
        self.re_http = re.compile(r'http[s]?://')
        self.re_rtsp = re.compile(r'rtsp://')
        self.re_rtmp = re.compile(r'rtmp://')
        self.re_mms = re.compile(r'mms://')
    
    def stop(self):
        """ç«‹å³åœæ­¢éªŒè¯è¿‡ç¨‹ï¼Œç»ˆæ­¢æ‰€æœ‰çº¿ç¨‹å’Œè¿›ç¨‹"""
        self.stop_requested = True
        
        # å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„futureå¯¹è±¡
        # åˆ›å»ºé›†åˆçš„å‰¯æœ¬è¿›è¡Œè¿­ä»£ï¼Œé¿å…"Set changed size during iteration"é”™è¯¯
        for future in list(self._active_futures):
            try:
                future.cancel()
            except Exception:
                pass
        # æ¸…ç©ºæ´»è·ƒfutureé›†åˆ
        self._active_futures.clear()
        
        # å¦‚æœæœ‰éªŒè¯çº¿ç¨‹æ± ï¼Œç«‹å³å…³é—­å®ƒ
        if hasattr(self, '_validation_pool') and self._validation_pool:
            try:
                # ç«‹å³å…³é—­çº¿ç¨‹æ± ï¼Œä¸ç­‰å¾…ä»»åŠ¡å®Œæˆ
                self._validation_pool.shutdown(wait=False)
                self._validation_pool = None  # é‡Šæ”¾å¼•ç”¨
            except Exception:
                pass
        
        # å¦‚æœæœ‰ffprobeçº¿ç¨‹æ± ï¼Œç«‹å³å…³é—­å®ƒè€Œä¸ç­‰å¾…
        if self.ffprobe_pool:
            self.ffprobe_pool.shutdown(wait=False)
            self.ffprobe_pool = None  # é‡Šæ”¾å¼•ç”¨
        
        # å¦‚æœæœ‰HTTPä¼šè¯ï¼Œç«‹å³å…³é—­å®ƒ
        if hasattr(self, 'session') and self.session:
            try:
                # å…³é—­æ‰€æœ‰è¿æ¥
                self.session.close()
            except Exception:
                pass
            self.session = None  # é‡Šæ”¾å¼•ç”¨
        
        # æ¸…ç†å·²å¤„ç†çš„å¤–éƒ¨URLé›†åˆï¼Œé‡Šæ”¾å†…å­˜
        if hasattr(self, 'processed_external_urls'):
            self.processed_external_urls.clear()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾èµ„æº
        import gc
        gc.collect()

    def _init_http_session(self):
        """åˆå§‹åŒ–HTTPä¼šè¯ï¼Œé…ç½®è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•æœºåˆ¶
        retry = Retry(
            total=3,
            backoff_factor=0.5,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET"]
        )
        
        # é…ç½®HTTPé€‚é…å™¨å’Œè¿æ¥æ± 
        adapter = HTTPAdapter(
            max_retries=retry,
            pool_connections=50,
            pool_maxsize=50
        )
        
        # ä¸ºhttpå’Œhttpsåè®®æŒ‚è½½é€‚é…å™¨
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        return session

    def _detect_file_type(self):
        """æ£€æµ‹è¾“å…¥æ–‡ä»¶ç±»å‹ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶å’Œäº’è”ç½‘URL"""
        print(f"[è°ƒè¯•] æ£€æµ‹æ–‡ä»¶ç±»å‹: {self.input_file}")
        # æ£€æŸ¥æ˜¯å¦ä¸ºHTTP/HTTPS URL
        if self.input_file.startswith(('http://', 'https://')):
            print("[è°ƒè¯•] æ£€æµ‹åˆ°URLï¼Œå¼€å§‹ä¸‹è½½æ–‡ä»¶")
            # ä¸‹è½½æ–‡ä»¶å¹¶æ£€æµ‹ç±»å‹
            self.input_file = self._download_url(self.input_file)
            print(f"[è°ƒè¯•] ä¸‹è½½å®Œæˆï¼Œæ–°æ–‡ä»¶è·¯å¾„: {self.input_file}")
            # é‡æ–°æ£€æµ‹ä¸‹è½½åçš„æ–‡ä»¶ç±»å‹
            if self.input_file.endswith('.m3u') or self.input_file.endswith('.m3u8'):
                return 'm3u'
            elif self.input_file.endswith('.txt'):
                return 'txt'
            else:
                # è¯»å–æ–‡ä»¶å†…å®¹æ£€æµ‹
                try:
                    with open(self.input_file, 'r', encoding='utf-8') as f:
                        content = f.read(1024)
                        if content.startswith('#EXTM3U'):
                            return 'm3u'
                        elif content and ('#genre#' in content or '\t' in content):
                            return 'txt'
                        elif content:
                            return 'txt'
                except Exception:
                    pass
                return 'txt'
        elif self.input_file.endswith('.m3u') or self.input_file.endswith('.m3u8'):
            return 'm3u'
        elif self.input_file.endswith('.txt'):
            return 'txt'
        else:
            # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹æ£€æµ‹
            try:
                with open(self.input_file, 'r', encoding='utf-8') as f:
                    content = f.read(1024)
                    if content.startswith('#EXTM3U'):
                        return 'm3u'
                    elif content and ('#genre#' in content or '\t' in content):
                        return 'txt'
                    elif content:
                        return 'txt'
            except Exception:
                pass
            return 'txt'

    def _check_ffprobe_availability(self):
        """æ£€æŸ¥ffprobeæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ['ffprobe', '-version'],
                capture_output=True, text=True, timeout=5,
                shell=False
            )
            return result.returncode == 0
        except Exception:
            return False

    def _check_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        output_dir = os.path.dirname(self.output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

    def _generate_output_filename(self):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼‰"""
        if self.original_filename:
            base = os.path.splitext(os.path.basename(self.original_filename))[0]
        else:
            base = os.path.splitext(os.path.basename(self.input_file))[0]
        if self.file_type == 'm3u':
            filename = f"{base}_valid.m3u"
        else:
            filename = f"{base}_valid.txt"
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_dir = os.path.join(script_dir, 'output')
        return os.path.join(output_dir, filename)

    def _download_url(self, url, timeout=30):
        """ä¸‹è½½URLå†…å®¹åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            response = requests.get(url, timeout=timeout, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }, allow_redirects=True)
            response.raise_for_status()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            fd, temp_path = tempfile.mkstemp(suffix='.txt')
            with os.fdopen(fd, 'wb') as f:
                f.write(response.content)
            return temp_path
        except Exception as e:
            print(f"[é”™è¯¯] ä¸‹è½½URLå¤±è´¥: {url}, é”™è¯¯: {str(e)}")
            return None

    def _http_request_with_retry(self, url, method='head', timeout=None, headers=None, retries=3):
        """å‘é€HTTPè¯·æ±‚ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        if self.stop_requested:
            return None
            
        if timeout is None:
            timeout = self.timeouts['http_head']
        
        session = self.session
        retry_strategy = Retry(
            total=retries,
            backoff_factor=0.5,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        for attempt in range(retries + 1):
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            if self.stop_requested:
                return None
            
            try:
                if method.lower() == 'head':
                    response = session.head(url, timeout=timeout, headers=headers, allow_redirects=True)
                else:
                    response = session.get(url, timeout=timeout, headers=headers, allow_redirects=True)
                
                if response.status_code < 400:
                    return response
                elif response.status_code == 429:  # Too Many Requests
                    wait_time = (attempt + 1) * 2
                    if self.debug:
                        print(f"[è°ƒè¯•] æ”¶åˆ°429é”™è¯¯ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    return None
                    
            except requests.exceptions.Timeout:
                if self.debug:
                    print(f"[è°ƒè¯•] è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{retries + 1}): {url}")
                if attempt < retries:
                    continue
                return None
            except requests.exceptions.RequestException as e:
                if self.debug:
                    print(f"[è°ƒè¯•] è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries + 1}): {url}, é”™è¯¯: {str(e)}")
                if attempt < retries:
                    continue
                return None
        
        return None

    def _parse_m3u_file(self):
        """è§£æM3Uæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯"""
        channels = []
        current_category = "æœªåˆ†ç±»"
        
        with open(self.input_file, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.splitlines()
            
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            if line.startswith('#EXTINF:'):
                name_match = self.re_extinf_name.search(line)
                name = name_match.group(1).strip() if name_match else "æœªçŸ¥é¢‘é“"
                
                group_match = self.re_group_title.search(line)
                if group_match:
                    current_category = group_match.group(1).strip()
                
                tvg_match = self.re_tvg_name.search(line)
                if tvg_match:
                    name = tvg_match.group(1).strip()
                
            elif line.startswith('#'):
                continue
            elif line.startswith('http://') or line.startswith('https://'):
                channels.append({
                    'name': name,
                    'url': line.strip(),
                    'category': current_category
                })
            elif not line.startswith('#'):
                if self.re_category.match(line):
                    current_category = self.re_category.match(line).group(1).strip()
                    
        return channels

    def _parse_txt_file(self):
        """è§£æTXTæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯"""
        channels = []
        current_category = "æœªåˆ†ç±»"
        
        with open(self.input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            if self.re_category.match(line):
                current_category = self.re_category.match(line).group(1).strip()
                continue
            
            if ',' in line:
                parts = line.split(',', 1)
                if len(parts) == 2:
                    name = parts[0].strip()
                    url = parts[1].strip()
                    if url:
                        channels.append({
                            'name': name,
                            'url': url,
                            'category': current_category
                        })
            elif '\t' in line:
                parts = line.split('\t', 1)
                if len(parts) == 2:
                    name = parts[0].strip()
                    url = parts[1].strip()
                    if url:
                        channels.append({
                            'name': name,
                            'url': url,
                            'category': current_category
                        })
                        
        return channels

    def _extract_resolution_from_url(self, url):
        """ä»URLä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼Œè¿”å›(å®½åº¦, é«˜åº¦)å…ƒç»„"""
        # å°è¯•ä»URLä¸­çš„åˆ†è¾¨ç‡æ ‡æ³¨æå–
        match = self.re_resolution.search(url)
        if match:
            res = match.group(1)
            parts = res.split('*')
            if len(parts) == 2:
                return parts[0], parts[1]
        
        # å°è¯•ä»URLå‚æ•°ä¸­æå–åˆ†è¾¨ç‡
        dollar_match = self.re_url_resolution_dollar.search(url)
        if dollar_match:
            return dollar_match.group(1), dollar_match.group(2)
        
        param_match = self.re_url_resolution_param.search(url)
        if param_match:
            return param_match.group(1), param_match.group(2)
        
        res_match = self.re_url_res_param.search(url)
        if res_match:
            width = res_match.group(1)
            # å¸¸è§çš„åˆ†è¾¨ç‡å®½åº¦å¯¹åº”é«˜åº¦
            height_map = {
                '720': '720',
                '1080': '1080',
                '4k': '2160',
                '2160': '2160'
            }
            height = height_map.get(width, width)
            return width, height
        
        return None, None

    def _validate_url(self, channel, original_index=None):
        """éªŒè¯å•ä¸ªURL"""
        if self.stop_requested:
            return None
            
        name = channel.get('name', 'æœªçŸ¥é¢‘é“')
        url = channel.get('url', '')
        category = channel.get('category', 'æœªåˆ†ç±»')
        
        if original_index is None:
            original_index = channel.get('original_index', 0)
        
        if not url:
            return None
        
        result = {
            'name': name,
            'url': url,
            'category': category,
            'original_index': original_index,
            'valid': False,
            'resolution': None,
            'resolution_width': None,
            'resolution_height': None,
            'codec': None,
            'audio': None,
            'error': None
        }
        
        # é¦–å…ˆæ£€æŸ¥URLæ ¼å¼
        if not (url.startswith('http://') or url.startswith('https://') or 
                url.startswith('rtsp://') or url.startswith('rtmp://') or 
                url.startswith('udp://') or url.startswith('rtp://')):
            result['error'] = 'ä¸æ”¯æŒçš„URLåè®®'
            return result
        
        # å¯¹äºHTTP(S) URLè¿›è¡Œå¿«é€ŸHEADè¯·æ±‚æ£€æŸ¥
        if url.startswith('http://') or url.startswith('https://'):
            # æ£€æµ‹IPv6åœ°å€æ ¼å¼ï¼ˆåŒ…å«æ–¹æ‹¬å·ï¼Œå¦‚ http://[2409:8087:8:21::0b]:6610/ï¼‰
            is_ipv6 = '[' in url and ']' in url
            
            # è·³è¿‡UDPä»£ç†URL(HTTPä»£ç†UDPæµçš„ç‰¹æ®Šæ ¼å¼)
            if '/udp/' in url.lower() or '/rtp/' in url.lower() or '/rtmp/' in url.lower():
                result['valid'] = True
                result['error'] = None
                width, height = self._extract_resolution_from_url(url)
                result['resolution_width'] = width
                result['resolution_height'] = height
                if width and height:
                    result['resolution'] = f"{width}*{height}"
                return result
            
            # IPv6 URLè·³è¿‡HTTPè¯·æ±‚ï¼Œåˆæ­¥æ ‡è®°ä¸ºæœ‰æ•ˆï¼Œç»§ç»­è¿›è¡Œåˆ†è¾¨ç‡æ£€æµ‹
            if is_ipv6:
                result['valid'] = True
                result['error'] = None
                result['is_ipv6'] = True
            else:
                response = self._http_request_with_retry(url, method='head', timeout=self.timeouts['http_head'])
                if not response:
                    response = self._http_request_with_retry(url, method='get', timeout=self.timeouts['http_get'])
                
                if response:
                    result['valid'] = True
                else:
                    result['error'] = 'HTTPè¯·æ±‚å¤±è´¥'
                    return result
        else:
            result['is_ipv6'] = False
        
        # å¯¹äºéHTTP URL,ä½¿ç”¨BlackBird-Playeré£æ ¼çš„è¯•æ’­éªŒè¯æ¥çœŸæ­£åˆ¤æ–­æœ‰æ•ˆæ€§
        if url.startswith('udp://') or url.startswith('rtsp://') or url.startswith('rtmp://') or url.startswith('rtp://'):
            result['is_special_protocol'] = True
            if self.ffprobe_available and not self.skip_resolution:
                playback_result = _test_stream_playback(url, self.timeouts['ffprobe'])
                if playback_result and playback_result[0]:
                    result['valid'] = True
                    result['error'] = None
                    result['resolution'], result['codec'], result['audio'] = playback_result
                    if result['resolution']:
                        res_parts = result['resolution'].split('*')
                        if len(res_parts) == 2:
                            result['resolution_width'] = res_parts[0]
                            result['resolution_height'] = res_parts[1]
                else:
                    result['valid'] = False
                    error_info = playback_result[2] if playback_result else {}
                    result['error'] = error_info.get('error', 'è¯•æ’­å¤±è´¥')
                    return result
            else:
                result['valid'] = True
                result['error'] = None
                width, height = self._extract_resolution_from_url(url)
                result['resolution_width'] = width
                result['resolution_height'] = height
                if width and height:
                    result['resolution'] = f"{width}*{height}"
            return result
        
        # IPv6 URLä½¿ç”¨BlackBird-Playeré£æ ¼çš„è¯•æ’­éªŒè¯
        # é‡‡ç”¨BlackBird-Playerçš„ç­–ç•¥ï¼šå¯¹äºç‰¹æ®Šæ ¼å¼çš„ç›´æ’­æºï¼ˆUDP/RTSP/RTMP/IPv6ï¼‰ï¼Œé€šè¿‡è¯•æ’­çœŸæ­£éªŒè¯æœ‰æ•ˆæ€§
        if result.get('is_ipv6'):
            if self.ffprobe_available and not self.skip_resolution:
                playback_result = _test_stream_playback(url, self.timeouts['ffprobe'])
                if playback_result and playback_result[0]:
                    result['valid'] = True
                    result['error'] = None
                    result['resolution'], result['codec'], result['audio'] = playback_result
                    if result['resolution']:
                        res_parts = result['resolution'].split('*')
                        if len(res_parts) == 2:
                            result['resolution_width'] = res_parts[0]
                            result['resolution_height'] = res_parts[1]
                else:
                    error_info = playback_result[2] if playback_result else {}
                    result['error'] = error_info.get('error', 'IPv6è¯•æ’­å¤±è´¥')
                    if 'IPv6' in result['error']:
                        result['valid'] = True
                        width, height = self._extract_resolution_from_url(url)
                        result['resolution_width'] = width
                        result['resolution_height'] = height
                        if width and height:
                            result['resolution'] = f"{width}*{height}"
                    else:
                        result['valid'] = False
                        return result
            else:
                result['valid'] = True
                result['error'] = None
                width, height = self._extract_resolution_from_url(url)
                result['resolution_width'] = width
                result['resolution_height'] = height
                if width and height:
                    result['resolution'] = f"{width}*{height}"
            return result
        
        # å¦‚æœå¯ç”¨äº†ffprobeä¸”ä¸æ˜¯è·³è¿‡åˆ†è¾¨ç‡æ£€æµ‹ï¼Œè·å–åˆ†è¾¨ç‡
        if self.ffprobe_available and not self.skip_resolution and result['valid']:
            resolution_info = self._get_resolution_with_fallback(url)
            if resolution_info:
                result['resolution'], result['codec'], result['audio'] = resolution_info
                if result['resolution']:
                    res_parts = result['resolution'].split('*')
                    if len(res_parts) == 2:
                        result['resolution_width'] = res_parts[0]
                        result['resolution_height'] = res_parts[1]
            else:
                result['resolution'] = None
        
        # å¦‚æœéœ€è¦æ£€æŸ¥éŸ³é¢‘æµ
        if self.filter_no_audio and result['valid']:
            has_audio = _check_url_has_audio(url, self.timeouts['ffprobe'])
            if not has_audio:
                result['valid'] = False
                result['error'] = 'æ— éŸ³é¢‘æµ'
        
        return result

    def _get_resolution_with_fallback(self, url):
        """è·å–åˆ†è¾¨ç‡ï¼Œæ”¯æŒå¤šç§æ£€æµ‹æ–¹æ³•çš„fallback"""
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        if self.stop_requested:
            return None
        
        timeout = self.timeouts['ffprobe']
        
        # æ–¹æ³•1: å°è¯•ä»HLSæ’­æ”¾åˆ—è¡¨æå–åˆ†è¾¨ç‡
        if url.endswith('.m3u8') or url.endswith('.m3u') or '/hls/' in url.lower() or '/live/' in url.lower():
            resolution = _get_resolution_from_hls(url, timeout)
            if resolution and resolution[0]:
                return resolution
        
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        if self.stop_requested:
            return None
        
        # æ–¹æ³•2: å°è¯•ä½¿ç”¨ffprobeç›´æ¥æ£€æµ‹
        resolution = _ffprobe_get_resolution(url, timeout)
        if resolution and resolution[0]:
            return resolution
        
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        if self.stop_requested:
            return None
        
        # æ–¹æ³•3: å¦‚æœæœ‰MediaInfoä½œä¸ºå¤‡é€‰
        if self.mediainfo_available:
            resolution = _mediainfo_get_resolution(url, timeout)
            if resolution:
                return resolution, 'unknown', {'source': 'mediainfo'}
        
        return None

    def _run_validation(self, progress_callback=None):
        """è¿è¡ŒéªŒè¯è¿‡ç¨‹"""
        print(f"å¼€å§‹éªŒè¯: {self.input_file}")
        
        # æ¸…é™¤ä¹‹å‰çš„éªŒè¯ç»“æœç¼“å­˜
        self.all_results = []
        
        # è§£æè¾“å…¥æ–‡ä»¶
        if self.file_type == 'm3u':
            self.channels = self._parse_m3u_file()
        else:
            self.channels = self._parse_txt_file()
        
        total_channels = len(self.channels)
        print(f"å…±å‘ç° {total_channels} ä¸ªé¢‘é“")
        
        # å‘é€è§£æå®Œæˆè¿›åº¦
        if progress_callback:
            progress_callback({
                'progress': 10,
                'total_channels': total_channels,
                'processed': 0,
                'message': f'æ–‡ä»¶è§£æå®Œæˆï¼Œå…±æ‰¾åˆ°{total_channels}ä¸ªé¢‘é“ï¼Œå¼€å§‹éªŒè¯é¢‘é“æœ‰æ•ˆæ€§',
                'stage': 'parsing_completed'
            })
        
        # åˆ›å»ºéªŒè¯çº¿ç¨‹æ± å¹¶ä¿å­˜åˆ°å®ä¾‹å˜é‡
        self._validation_pool = concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers)
        
        try:
            futures = []
            for idx, channel in enumerate(self.channels):
                if self.stop_requested:
                    break
                channel['original_index'] = idx
                future = self._validation_pool.submit(self._validate_url, channel)
                futures.append(future)
                self._active_futures.add(future)
            
            # æ”¶é›†ç»“æœå¹¶å‘é€è¿›åº¦æ›´æ–°
            processed_count = 0
            for future in concurrent.futures.as_completed(futures):
                self._active_futures.discard(future)
                if self.stop_requested:
                    continue
                    
                try:
                    result = future.result()
                    if result:
                        self.all_results.append(result)
                        processed_count += 1
                        
                        # å‘é€è¿›åº¦æ›´æ–°
                        if progress_callback:
                            progress_callback({
                                'progress': 10 + int(processed_count / total_channels * 80),
                                'total_channels': total_channels,
                                'processed': processed_count,
                                'message': f'éªŒè¯ä¸­: {result.get("name", "æœªçŸ¥é¢‘é“")} - {result.get("status", "")}',
                                'stage': 'validation',
                                'channel': result
                            })
                except Exception as e:
                    if self.debug:
                        print(f"[è°ƒè¯•] éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
                    
                    processed_count += 1
                    if progress_callback:
                        progress_callback({
                            'progress': 10 + int(processed_count / total_channels * 80),
                            'total_channels': total_channels,
                            'processed': processed_count,
                            'message': f'éªŒè¯å‡ºé”™: {str(e)}',
                            'stage': 'validation'
                        })
        finally:
            # ç¡®ä¿å…³é—­çº¿ç¨‹æ± 
            if self._validation_pool:
                self._validation_pool.shutdown(wait=False)
                self._validation_pool = None
        
        # æŒ‰original_indexæ’åºï¼Œä¿æŒåŸæ–‡ä»¶ä¸­çš„é¢‘é“é¡ºåº
        self.all_results.sort(key=lambda x: x.get('original_index', 0))
        
        print(f"éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆé¢‘é“: {sum(1 for r in self.all_results if r['valid'])}/{len(self.all_results)}")

    def _generate_m3u_output(self):
        """ç”ŸæˆM3Uæ ¼å¼è¾“å‡ºæ–‡ä»¶"""
        output_lines = ['#EXTM3U']
        
        # æŒ‰åˆ†ç±»ç»„ç»‡ç»“æœ
        categorized = {}
        for result in self.all_results:
            if not result['valid']:
                continue
            
            category = result['category'] or 'æœªåˆ†ç±»'
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(result)
        
        for category, channels in sorted(categorized.items()):
            for channel in channels:
                extinf = f'#EXTINF:-1 tvg-name="{channel["name"]}" group-title="{category}"'
                if channel['resolution']:
                    extinf += f' tvg-shift=1,{channel["name"]}[{channel["resolution"]}]'
                else:
                    extinf += f',{channel["name"]}'
                output_lines.append(extinf)
                output_lines.append(channel['url'])
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(output_lines))
        
        print(f"M3Uè¾“å‡ºå·²ä¿å­˜åˆ°: {self.output_file}")

    def _generate_txt_output(self):
        """ç”ŸæˆTXTæ ¼å¼è¾“å‡ºæ–‡ä»¶"""
        output_lines = []
        
        # æ·»åŠ éªŒè¯æ—¶é—´æˆ³ - å‚è€ƒBlackBird-Playerçš„result.txtæ ¼å¼
        timestamp = ValidationTimestamp.get_timestamp()
        output_lines.append(f"ğŸ•˜ï¸æ›´æ–°æ—¶é—´,#genre#")
        output_lines.append(f"{timestamp}")
        output_lines.append("")
        
        # æŒ‰åˆ†ç±»ç»„ç»‡ç»“æœ
        categorized = {}
        for result in self.all_results:
            if not result['valid']:
                continue
            
            category = result['category'] or 'æœªåˆ†ç±»'
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(result)
        
        for category, channels in sorted(categorized.items()):
            output_lines.append(f"{category},#genre#")
            for channel in channels:
                if channel['resolution']:
                    output_lines.append(f'{channel["name"]}[{channel["resolution"]}],{channel["url"]}')
                else:
                    output_lines.append(f'{channel["name"]},{channel["url"]}')
            output_lines.append("")
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(output_lines))
        
        print(f"TXTè¾“å‡ºå·²ä¿å­˜åˆ°: {self.output_file}")

    def run(self):
        """è¿è¡Œå®Œæ•´çš„éªŒè¯è¿‡ç¨‹"""
        try:
            # æ›´æ–°éªŒè¯æ—¶é—´æˆ³
            ValidationTimestamp.update_timestamp()
            
            # è¿è¡ŒéªŒè¯
            self._run_validation()
            
            # ç”Ÿæˆè¾“å‡º
            if self.file_type == 'm3u':
                self._generate_m3u_output()
            else:
                self._generate_txt_output()
            
            return self.output_file
            
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­éªŒè¯è¿‡ç¨‹")
            return None
        except Exception as e:
            print(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            if self.debug:
                import traceback
                traceback.print_exc()
            return None

    def read_m3u_file(self, progress_callback=None):
        """è§£æM3Uæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯ï¼ˆå…¬å¼€æ¥å£ï¼‰"""
        self.channels = self._parse_m3u_file()
        if progress_callback:
            progress_callback({
                'progress': 5,
                'total_channels': len(self.channels),
                'processed': 0,
                'message': f'M3Uæ–‡ä»¶è§£æå®Œæˆï¼Œå…±æ‰¾åˆ°{len(self.channels)}ä¸ªé¢‘é“'
            })
        return self.channels

    def read_txt_file(self, progress_callback=None):
        """è§£æTXTæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯ï¼ˆå…¬å¼€æ¥å£ï¼‰"""
        self.channels = self._parse_txt_file()
        if progress_callback:
            progress_callback({
                'progress': 5,
                'total_channels': len(self.channels),
                'processed': 0,
                'message': f'TXTæ–‡ä»¶è§£æå®Œæˆï¼Œå…±æ‰¾åˆ°{len(self.channels)}ä¸ªé¢‘é“'
            })
        return self.channels

    def read_json_file(self, progress_callback=None):
        """è§£æJSONæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯ï¼ˆå…¬å¼€æ¥å£ï¼‰"""
        self.channels = self._parse_json_file()
        if progress_callback:
            progress_callback({
                'progress': 5,
                'total_channels': len(self.channels),
                'processed': 0,
                'message': f'JSONæ–‡ä»¶è§£æå®Œæˆï¼Œå…±æ‰¾åˆ°{len(self.channels)}ä¸ªé¢‘é“'
            })
        return self.channels

    def _parse_json_file(self):
        """è§£æJSONæ–‡ä»¶ï¼Œæå–é¢‘é“ä¿¡æ¯"""
        import json
        channels = []
        try:
            with open(self.input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict) and 'url' in item:
                        channels.append({
                            'name': item.get('name', 'æœªçŸ¥é¢‘é“'),
                            'url': item['url'],
                            'category': item.get('category', 'æœªåˆ†ç±»')
                        })
            elif isinstance(data, dict):
                for name, url in data.items():
                    if isinstance(url, str):
                        channels.append({
                            'name': name,
                            'url': url,
                            'category': 'æœªåˆ†ç±»'
                        })
        except Exception as e:
            print(f"[é”™è¯¯] è§£æJSONæ–‡ä»¶å¤±è´¥: {str(e)}")
        return channels

    def validate_channels(self, progress_callback=None):
        """éªŒè¯æ‰€æœ‰é¢‘é“ï¼ˆå…¬å¼€æ¥å£ï¼‰"""
        self._run_validation(progress_callback=progress_callback)
        if progress_callback:
            progress_callback({
                'progress': 90,
                'total_channels': len(self.channels),
                'processed': len(self.all_results),
                'message': f'éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆé¢‘é“: {sum(1 for r in self.all_results if r["valid"])}/{len(self.all_results)}',
                'stage': 'validation_completed'
            })
        return self.all_results

    def generate_output_files(self):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶ï¼ˆå…¬å¼€æ¥å£ï¼‰"""
        if self.file_type == 'm3u':
            self._generate_m3u_output()
        else:
            self._generate_txt_output()
        return self.output_file

    def get_results_summary(self):
        """è·å–éªŒè¯ç»“æœæ‘˜è¦"""
        total = len(self.all_results)
        valid = sum(1 for r in self.all_results if r['valid'])
        invalid = total - valid
        
        resolution_stats = {}
        for result in self.all_results:
            if result['resolution']:
                res = result['resolution']
                resolution_stats[res] = resolution_stats.get(res, 0) + 1
        
        return {
            'total': total,
            'valid': valid,
            'invalid': invalid,
            'valid_rate': f"{valid/total*100:.1f}%" if total > 0 else "0%",
            'resolution_stats': resolution_stats
        }

    def get_results_by_category(self):
        """æŒ‰åˆ†ç±»è·å–éªŒè¯ç»“æœ"""
        categorized = {}
        for result in self.all_results:
            if not result['valid']:
                continue
            
            category = result['category'] or 'æœªåˆ†ç±»'
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(result)
        
        return categorized


def validate_ipTV(input_file, output_file=None, max_workers=None, timeout=5, debug=False, original_filename=None, skip_resolution=False, filter_no_audio=False):
    """
    éªŒè¯IPTVç›´æ’­æº
    
    å‚æ•°:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–URL
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨è®¡ç®—ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        original_filename: åŸå§‹æ–‡ä»¶åï¼ˆç”¨äºç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼‰
        skip_resolution: æ˜¯å¦è·³è¿‡åˆ†è¾¨ç‡æ£€æµ‹
        filter_no_audio: æ˜¯å¦è¿‡æ»¤æ— éŸ³é¢‘æµçš„é¢‘é“
    
    è¿”å›:
        éªŒè¯ç»“æœæ‘˜è¦å­—å…¸
    """
    validator = IPTVValidator(
        input_file=input_file,
        output_file=output_file,
        max_workers=max_workers,
        timeout=timeout,
        debug=debug,
        original_filename=original_filename,
        skip_resolution=skip_resolution,
        filter_no_audio=filter_no_audio
    )
    
    output_path = validator.run()
    summary = validator.get_results_summary()
    
    if output_path:
        summary['output_file'] = output_path
        print(f"\néªŒè¯æ‘˜è¦:")
        print(f"  æ€»é¢‘é“æ•°: {summary['total']}")
        print(f"  æœ‰æ•ˆé¢‘é“: {summary['valid']}")
        print(f"  æ— æ•ˆé¢‘é“: {summary['invalid']}")
        print(f"  æœ‰æ•ˆç‡: {summary['valid_rate']}")
        
        if summary['resolution_stats']:
            print(f"  åˆ†è¾¨ç‡åˆ†å¸ƒ:")
            for res, count in sorted(summary['resolution_stats'].items(), key=lambda x: int(x[0].split('*')[1]), reverse=True):
                print(f"    {res}: {count}ä¸ª")
    
    return summary


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='IPTVç›´æ’­æºéªŒè¯å·¥å…·')
    parser.add_argument('input', help='è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–URL')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-w', '--workers', type=int, help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('-t', '--timeout', type=int, default=5, help='è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('-d', '--debug', action='store_true', help='å¼€å¯è°ƒè¯•æ¨¡å¼')
    parser.add_argument('-s', '--skip-resolution', action='store_true', help='è·³è¿‡åˆ†è¾¨ç‡æ£€æµ‹')
    parser.add_argument('--no-audio-filter', action='store_true', help='è¿‡æ»¤æ— éŸ³é¢‘æµçš„é¢‘é“')
    
    args = parser.parse_args()
    
    validate_ipTV(
        input_file=args.input,
        output_file=args.output,
        max_workers=args.workers,
        timeout=args.timeout,
        debug=args.debug,
        skip_resolution=args.skip_resolution,
        filter_no_audio=args.no_audio_filter
    )
