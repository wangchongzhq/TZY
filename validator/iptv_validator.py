#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ’­æºæœ‰æ•ˆæ€§éªŒè¯å·¥å…·
åŠŸèƒ½ï¼šéªŒè¯M3Uå’ŒTXTæ ¼å¼ç›´æ’­æºæ–‡ä»¶ä¸­çš„URLæœ‰æ•ˆæ€§ï¼Œæ£€æµ‹è§†é¢‘åˆ†è¾¨ç‡ï¼Œå¹¶ç”Ÿæˆæ–°çš„ç›´æ’­æºæ–‡ä»¶
"""

import os
import re
import json
import time
import subprocess
import concurrent.futures
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import tempfile
import multiprocessing
from urllib.parse import urlparse


def _ffprobe_get_resolution(url, timeout):
    """åœ¨è¿›ç¨‹æ± ä¸­æ‰§è¡Œçš„ffprobeåˆ†è¾¨ç‡æ£€æµ‹å‡½æ•°"""
    import subprocess
    import json
    try:
        # ä½¿ç”¨ffprobeè·å–è§†é¢‘ä¿¡æ¯
        cmd = [
            'ffprobe', '-v', 'error', '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height', '-of', 'json', url
        ]

        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout,
            shell=False, encoding='utf-8', errors='ignore'
        )

        if result.returncode != 0:
            return None

        output = json.loads(result.stdout)
        if 'streams' in output and len(output['streams']) > 0:
            stream = output['streams'][0]
            if 'width' in stream and 'height' in stream:
                return f"{stream['width']}*{stream['height']}"
        return None
    except Exception:
        return None


class IPTVValidator:
    def __init__(self, input_file, output_file=None, max_workers=None, timeout=5, debug=False):
        self.input_file = input_file
        # åŠ¨æ€è®¡ç®—çº¿ç¨‹æ± å¤§å°
        self.max_workers = max_workers or min(20, multiprocessing.cpu_count() * 4)
        self.debug = debug
        self.channels = []
        self.categories = []
        # æ‰¹æ¬¡å¤§å°ï¼Œç”¨äºåˆ†æ‰¹æ¬¡å¤„ç†é¢‘é“
        self.batch_size = 50
        
        # æ·»åŠ åœæ­¢æ ‡å¿—
        self.stop_requested = False
        
        # è·Ÿè¸ªå·²å¤„ç†çš„å¤–éƒ¨URLï¼Œé˜²æ­¢é‡å¤æ·»åŠ é¢‘é“
        self.processed_external_urls = set()
        
        # åˆ†çº§è¶…æ—¶ç­–ç•¥
        self.timeouts = {
            'http_head': min(timeout, 3),  # HEADè¯·æ±‚è¶…æ—¶æ›´çŸ­
            'http_get': timeout,           # GETè¯·æ±‚ä½¿ç”¨é»˜è®¤è¶…æ—¶
            'non_http': min(timeout * 2, 10),  # éHTTPåè®®è¶…æ—¶æ›´é•¿
            'ffprobe': min(timeout * 2, 10)     # ffprobeè¶…æ—¶æ›´é•¿
        }
        
        # åˆå§‹åŒ–HTTPä¼šè¯å’Œè¿æ¥æ± 
        self.session = self._init_http_session()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self._check_output_dir()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        self.output_file = output_file or self._generate_output_filename()
        
        # æ£€æµ‹æ–‡ä»¶ç±»å‹å’Œffprobeå¯ç”¨æ€§
        self.file_type = self._detect_file_type()
        self.ffprobe_available = self._check_ffprobe_availability()
        
        # åˆå§‹åŒ–ffprobeè¿›ç¨‹æ± 
        self.ffprobe_pool = None
        if self.ffprobe_available:
            # ä½¿ç”¨ä¸CPUæ ¸å¿ƒæ•°ç›¸åŒçš„è¿›ç¨‹æ± å¤§å°
            self.ffprobe_pool = concurrent.futures.ProcessPoolExecutor(max_workers=multiprocessing.cpu_count())
            
    def stop(self):
        """è¯·æ±‚åœæ­¢éªŒè¯è¿‡ç¨‹"""
        self.stop_requested = True
        # å¦‚æœæœ‰ffprobeè¿›ç¨‹æ± ï¼Œå…³é—­å®ƒ
        if self.ffprobe_pool:
            self.ffprobe_pool.shutdown(wait=False)

    def _init_http_session(self):
        """åˆå§‹åŒ–HTTPä¼šè¯ï¼Œé…ç½®è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•æœºåˆ¶
        retry = Retry(
            total=3,
            backoff_factor=0.5,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET"]
        )
        
        # é…ç½®HTTPé€‚é…å™¨å’Œè¿æ¥æ± 
        adapter = HTTPAdapter(
            max_retries=retry,
            pool_connections=50,
            pool_maxsize=50
        )
        
        # ä¸ºhttpå’Œhttpsåè®®æŒ‚è½½é€‚é…å™¨
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        return session

    def _detect_file_type(self):
        """æ£€æµ‹è¾“å…¥æ–‡ä»¶ç±»å‹ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶å’Œäº’è”ç½‘URL"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºHTTP/HTTPS URL
        if self.input_file.startswith(('http://', 'https://')):
            # ä¸‹è½½æ–‡ä»¶å¹¶æ£€æµ‹ç±»å‹
            self.input_file = self._download_url(self.input_file)
            # é‡æ–°æ£€æµ‹ä¸‹è½½åçš„æ–‡ä»¶ç±»å‹
            if self.input_file.endswith('.m3u') or self.input_file.endswith('.m3u8'):
                return 'm3u'
            elif self.input_file.endswith('.txt'):
                return 'txt'
            elif self.input_file.endswith('.json'):
                return 'json'
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.m3uã€.m3u8ã€.txtå’Œ.jsonæ ¼å¼")
        # æœ¬åœ°æ–‡ä»¶æ£€æµ‹
        elif self.input_file.endswith('.m3u') or self.input_file.endswith('.m3u8'):
            return 'm3u'
        elif self.input_file.endswith('.txt'):
            return 'txt'
        elif self.input_file.endswith('.json'):
            return 'json'
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.m3uã€.m3u8ã€.txtå’Œ.jsonæ ¼å¼")

    def _download_url(self, url):
        """ä»URLä¸‹è½½ç›´æ’­æºæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
        try:
            if self.debug:
                print(f"[è°ƒè¯•] æ­£åœ¨ä¸‹è½½URL: {url}")
            
            # è·å–æ–‡ä»¶åå’Œæ‰©å±•å
            parsed_url = urlparse(url)
            filename = os.path.basename(parsed_url.path) or 'temp_live_source'
            
            # å¦‚æœæ–‡ä»¶åæ²¡æœ‰æ‰©å±•åï¼Œæ ¹æ®å“åº”å¤´æˆ–URLå†…å®¹ç¡®å®š
            if not os.path.splitext(filename)[1]:
                # å‘é€è¯·æ±‚è·å–æ–‡ä»¶å†…å®¹
                response = self.session.get(url, timeout=self.timeouts['http_get'], allow_redirects=True, verify=False)
                response.raise_for_status()
                
                # æ ¹æ®å“åº”å¤´æˆ–å†…å®¹ç¡®å®šæ–‡ä»¶ç±»å‹
                content_type = response.headers.get('Content-Type', '')
                if 'mpegurl' in content_type or 'm3u' in content_type:
                    filename += '.m3u'
                elif 'json' in content_type:
                    filename += '.json'
                elif 'text/plain' in content_type:
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºJSONæ ¼å¼
                    try:
                        json.loads(response.text)
                        filename += '.json'
                    except json.JSONDecodeError:
                        filename += '.txt'
                else:
                    # å°è¯•æ ¹æ®å†…å®¹ç¡®å®š
                    content = response.text.lower()
                    if '#extm3u' in content:
                        filename += '.m3u'
                    else:
                        # å°è¯•è§£æä¸ºJSON
                        try:
                            json.loads(response.text)
                            filename += '.json'
                        except json.JSONDecodeError:
                            filename += '.txt'
            else:
                # æ–‡ä»¶åå·²æœ‰æ‰©å±•åï¼Œç›´æ¥ä¸‹è½½
                response = self.session.get(url, timeout=self.timeouts['http_get'], allow_redirects=True, verify=False)
                response.raise_for_status()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            temp_file_path = os.path.join(temp_dir, filename)
            
            # å†™å…¥æ–‡ä»¶å†…å®¹
            with open(temp_file_path, 'wb') as f:
                f.write(response.content)
            
            if self.debug:
                print(f"[è°ƒè¯•] æ–‡ä»¶å·²ä¸‹è½½åˆ°: {temp_file_path}")
            
            return temp_file_path
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] ä¸‹è½½URLå¤±è´¥: {type(e).__name__}: {e}")
            raise ValueError(f"æ— æ³•ä¸‹è½½URL: {url}, é”™è¯¯: {str(e)}")

    def _check_ffprobe_availability(self):
        """æ£€æŸ¥ffprobeæ˜¯å¦å¯ç”¨"""
        try:
            subprocess.run(['ffprobe', '-version'], capture_output=True, text=True, shell=False)
            return True
        except (subprocess.SubprocessError, FileNotFoundError):
            return False

    def _check_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # åˆ›å»ºoutputç›®å½•åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•ä¸‹
        os.makedirs(os.path.join(script_dir, 'output'), exist_ok=True)

    def _generate_output_filename(self):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        base_name, ext = os.path.splitext(os.path.basename(self.input_file))
        return os.path.join(script_dir, 'output', f"{base_name}_valid{ext}")

    def read_m3u_file(self, progress_callback=None):
        """è¯»å–M3Uæ ¼å¼æ–‡ä»¶ï¼Œè§£æé¢‘é“ä¿¡æ¯å’Œåˆ†ç±»ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        # æ¸…é™¤å·²å¤„ç†çš„å¤–éƒ¨URLç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è§£æéƒ½æ˜¯å…¨æ–°å¼€å§‹
        self.processed_external_urls.clear()
        
        channels = []
        categories = []
        current_category = None
        channel_buffer = {}
        processed_count = 0
        total_channels = 0
        update_interval = 10  # æ¯å¤„ç†10ä¸ªé¢‘é“å‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°

        # åªè¯»å–ä¸€æ¬¡æ–‡ä»¶
        with open(self.input_file, 'r', encoding='utf-8-sig', errors='replace') as f:
            lines = f.readlines()
        
        # è®¡ç®—æ€»é¢‘é“æ•°
        for line in lines:
            if self.stop_requested:
                print("è§£ææ–‡ä»¶è¿‡ç¨‹å·²è¢«åœæ­¢")
                break
            if line.strip().startswith('#EXTINF:'):
                total_channels += 1
        
        # è§£æé¢‘é“ä¿¡æ¯
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                print("è§£ææ–‡ä»¶è¿‡ç¨‹å·²è¢«åœæ­¢")
                break
                
            line = line.strip()
            if not line:
                continue

            # è§£æEXTINFè¡Œï¼Œæå–é¢‘é“ä¿¡æ¯
            if line.startswith('#EXTINF:'):
                # æå–é¢‘é“åç§°ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼šæœ‰é€—å·å’Œæ²¡æœ‰é€—å·
                # 1. æ ‡å‡†æ ¼å¼ï¼š#EXTINF:-1 tvg-id="",é¢‘é“åç§°
                # 2. ç®€åŒ–æ ¼å¼ï¼š#EXTINF:-1 tvg-id="" tvg-name="é¢‘é“åç§°"
                name_match = re.search(r'#EXTINF:.*,(.+)', line)
                if name_match:
                    channel_buffer['name'] = name_match.group(1).strip()
                else:
                    # æ²¡æœ‰é€—å·çš„æƒ…å†µï¼Œå°è¯•ä»tvg-nameæå–
                    tvg_name_match = re.search(r'tvg-name="([^"]+)"', line)
                    if tvg_name_match:
                        channel_buffer['name'] = tvg_name_match.group(1).strip()
                    else:
                        # å°è¯•æå–æœ€åä¸€ä¸ªç©ºæ ¼åçš„å†…å®¹ä½œä¸ºé¢‘é“åç§°
                        parts = line.split()
                        if len(parts) > 1:
                            channel_buffer['name'] = parts[-1].strip()
                        else:
                            channel_buffer['name'] = "æœªå‘½åé¢‘é“"
                    # å¤„ç†ç©ºé¢‘é“åç§°çš„æƒ…å†µï¼Œé¿å…"no desc"æ˜¾ç¤º
                    if not channel_buffer['name']:
                        channel_buffer['name'] = "æœªå‘½åé¢‘é“"
                
                # å¤„ç†ç©ºé¢‘é“åç§°çš„æƒ…å†µï¼Œé¿å…"no desc"æ˜¾ç¤º
                if not channel_buffer.get('name'):
                    channel_buffer['name'] = "æœªå‘½åé¢‘é“"
                    
                # ä»é¢‘é“åç§°ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- é€‚ç”¨äºæ‰€æœ‰æ ¼å¼
                resolution_match = re.search(r'\[(\d+\*\d+)\]', channel_buffer['name'])
                channel_buffer['resolution_from_name'] = resolution_match.group(1) if resolution_match else None

                # æå–åˆ†ç±»ä¿¡æ¯
                category_match = re.search(r'group-title="([^"]+)"', line)
                if category_match:
                    channel_buffer['category'] = category_match.group(1)
                    if category_match.group(1) not in categories:
                        categories.append(category_match.group(1))

            # è§£æURLè¡Œ
            elif not line.startswith('#') and channel_buffer.get('name'):
                # å»é™¤URLä¸¤ç«¯çš„åå¼•å·å’Œç©ºç™½å­—ç¬¦
                url = line.strip().strip('`')
                channel_buffer['url'] = url
                channels.append(channel_buffer.copy())
                processed_count += 1
                
                # å‘é€è¿›åº¦æ›´æ–°ï¼Œæ¯å¤„ç†ä¸€å®šæ•°é‡çš„é¢‘é“å‘é€ä¸€æ¬¡
                if progress_callback and total_channels > 0 and processed_count % update_interval == 0:
                    progress = int((processed_count / total_channels) * 100)
                    progress_callback({
                        'progress': progress,
                        'total_channels': total_channels,
                        'processed': processed_count,
                        'channel': channel_buffer.copy(),
                        'stage': 'parsing'  # æ·»åŠ é˜¶æ®µä¿¡æ¯
                    })
                
                channel_buffer.clear()
        
        # å‘é€æœ€åä¸€æ¬¡è¿›åº¦æ›´æ–°
        if progress_callback and total_channels > 0:
            progress = int((processed_count / total_channels) * 100)
            progress_callback({
                'progress': progress,
                'total_channels': total_channels,
                'processed': processed_count,
                'channel': {'name': 'å®Œæˆè§£ææ–‡ä»¶'},
                'stage': 'parsing'
            })

        self.channels = channels
        self.categories = categories
        return channels, categories

    def read_txt_file(self, progress_callback=None):
        """è¯»å–TXTæ ¼å¼æ–‡ä»¶ï¼Œè§£æé¢‘é“ä¿¡æ¯å’Œåˆ†ç±»ï¼Œæ”¯æŒå¤–éƒ¨URLå¤„ç†å’Œè¿›åº¦å›è°ƒ"""
        # æ¸…é™¤å·²å¤„ç†çš„å¤–éƒ¨URLç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è§£æéƒ½æ˜¯å…¨æ–°å¼€å§‹
        self.processed_external_urls.clear()
        
        channels = []
        categories = []
        current_category = None
        all_lines = []
        processed_count = 0
        total_lines = 0

        # å…ˆè¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§ç¼–ç 
        try:
            with open(self.input_file, 'rb') as f:
                content = f.read()

            # æ£€æµ‹æ–‡ä»¶ç¼–ç  - å°è¯•å¤šç§ç¼–ç 
            encodings = ['utf-8-sig', 'gbk', 'mbcs', 'utf-16', 'latin-1']
            content_str = None
            
            for encoding in encodings:
                try:
                    content_str = content.decode(encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if content_str is None:
                # æ‰€æœ‰ç¼–ç éƒ½å°è¯•å¤±è´¥ï¼Œä½¿ç”¨latin-1ä½œä¸ºæœ€åçš„ä¿éšœ
                content_str = content.decode('latin-1', errors='replace')

            all_lines = content_str.splitlines()
            total_lines = len(all_lines)
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return channels, categories

        # é€è¡Œå¤„ç†æ–‡ä»¶å†…å®¹
        for line in all_lines:
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                print("è§£ææ–‡ä»¶è¿‡ç¨‹å·²è¢«åœæ­¢")
                break
                
            line = line.strip()
            if not line:
                processed_count += 1
                continue
                
            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line.startswith('//') or (line.startswith('#') and '#genre#' not in line):
                processed_count += 1
                continue

            # æ£€æµ‹åˆ†ç±»è¡Œï¼šæ”¯æŒå¤šç§æ ¼å¼ï¼ŒåŒ…æ‹¬#åˆ†ç±»å#,genre#å’Œemojiå¼€å¤´çš„åˆ†ç±»å,genre#
            category_match = re.search(r'([^,]+),#genre#', line)
            if category_match:
                current_category = category_match.group(1).strip()
                if current_category not in categories:
                    categories.append(current_category)
                processed_count += 1
                continue

            # è§£æé¢‘é“è¡Œï¼šé¢‘é“åç§°,é¢‘é“URL
            if ',' in line:
                try:
                    # æ”¹è¿›è§£æé€»è¾‘ï¼šæ”¯æŒé¢‘é“åç§°ä¸­åŒ…å«é€—å·çš„æƒ…å†µ
                    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«URLåè®®
                    url_pattern = r'(http[s]?://|rtsp://|rtmp://|mms://|udp://|rtp://)'
                    url_match = re.search(url_pattern, line)
                    if url_match:
                        # æ‰¾åˆ°URLçš„èµ·å§‹ä½ç½®ï¼Œå‰é¢çš„éƒ½æ˜¯é¢‘é“åç§°
                        url_start = url_match.start()
                        name = line[:url_start].rstrip(',').strip()
                        url = line[url_start:].strip().strip('`')
                    else:
                        # æ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„URLåè®®ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªé€—å·åˆ†å‰²
                        name, url = line.rsplit(',', 1)
                        name = name.strip()
                        url = url.strip().strip('`')
                    
                    # å¤„ç†ç©ºé¢‘é“åç§°çš„æƒ…å†µï¼Œé¿å…"no desc"æ˜¾ç¤º
                    if not name:
                        name = "æœªå‘½åé¢‘é“"
                    
                    if name and url:
                        # ä»é¢‘é“åç§°ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        resolution_match = re.search(r'\[(\d+\*\d+)\]', name)
                        resolution = resolution_match.group(1) if resolution_match else None
                        
                        # æ£€æŸ¥URLæ˜¯å¦ä¸ºå¤–éƒ¨ç›´æ’­æºæ–‡ä»¶
                        if self._is_external_source_file(url):
                            # å¤„ç†å¤–éƒ¨URLï¼Œä¸‹è½½å¹¶è§£æï¼Œä¼ é€’è¿›åº¦å›è°ƒ
                            external_channels, external_categories, _ = self._handle_external_url(url, current_category, progress_callback)
                            channels.extend(external_channels)
                            categories.extend([cat for cat in external_categories if cat not in categories])
                        else:
                            # æ™®é€šé¢‘é“ï¼Œç›´æ¥æ·»åŠ 
                            channel = {
                                'name': name,
                                'url': url,
                                'category': current_category if current_category else 'æœªåˆ†ç±»',
                                'resolution_from_name': resolution
                            }
                            channels.append(channel)
                            
                            # å‘é€è¿›åº¦æ›´æ–°
                            processed_count += 1
                            if progress_callback:
                                progress = int((processed_count / max(total_lines, 1)) * 100)
                                progress_callback({
                                    'progress': progress,
                                    'total_channels': max(total_lines, 1),
                                    'processed': processed_count,
                                    'channel': channel
                                })
                    else:
                        processed_count += 1
                except ValueError:
                    processed_count += 1
                    continue
            else:
                processed_count += 1

        # ç¡®ä¿æ‰€æœ‰åˆ†ç±»éƒ½å­˜åœ¨
        if not categories:
            categories.append('æœªåˆ†ç±»')
            current_category = 'æœªåˆ†ç±»'

        # å¦‚æœæ²¡æœ‰è§£æåˆ°ä»»ä½•é¢‘é“ï¼Œå°è¯•æ›´å®½æ¾çš„è§£ææ–¹å¼
        if not channels:
            for line in all_lines:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('//'):
                    continue
                # å°è¯•ç›´æ¥åŒ¹é…URL
                if re.search(r'http[s]?://', line) or re.search(r'rtsp://', line) or re.search(r'rtmp://', line) or re.search(r'mms://', line):
                    url = line.split(',')[-1].strip() if ',' in line else line.strip()
                    name = line.split(',')[0].strip() if ',' in line else 'æœªå‘½åé¢‘é“'
                    
                    # æ£€æŸ¥URLæ˜¯å¦ä¸ºå¤–éƒ¨ç›´æ’­æºæ–‡ä»¶
                    if self._is_external_source_file(url):
                        # å¤„ç†å¤–éƒ¨URLï¼Œä¸‹è½½å¹¶è§£æï¼Œä¼ é€’è¿›åº¦å›è°ƒ
                        external_channels, external_categories, _ = self._handle_external_url(url, 'æœªåˆ†ç±»', progress_callback)
                        channels.extend(external_channels)
                        categories.extend([cat for cat in external_categories if cat not in categories])
                    else:
                        # æ™®é€šé¢‘é“ï¼Œç›´æ¥æ·»åŠ 
                        # ä»é¢‘é“åç§°ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        resolution_match = re.search(r'\[(\d+\*\d+)\]', name)
                        resolution = resolution_match.group(1) if resolution_match else None
                        channels.append({
                            'name': name,
                            'url': url,
                            'category': 'æœªåˆ†ç±»',
                            'resolution_from_name': resolution
                        })

        self.channels = channels
        self.categories = categories
        return channels, categories
        
    def _is_external_source_file(self, url):
        """æ£€æŸ¥URLæ˜¯å¦æŒ‡å‘å¤–éƒ¨ç›´æ’­æºæ–‡ä»¶"""
        if not url.startswith(('http://', 'https://')):
            return False
            
        # æ£€æŸ¥URLæ˜¯å¦ä»¥ç›´æ’­æºæ–‡ä»¶æ‰©å±•åç»“å°¾ - åªå¤„ç†æ˜ç¡®çš„æ’­æ”¾åˆ—è¡¨æ–‡ä»¶
        url_lower = url.lower()
        if url_lower.endswith(('.m3u', '.m3u8')):
            return True
        
        # å¯¹äºtxtå’Œjsonæ–‡ä»¶ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„åˆ¤æ–­
        if url_lower.endswith(('.txt', '.json')):
            # æ£€æŸ¥URLè·¯å¾„ä¸­æ˜¯å¦åŒ…å«ç›´æ’­æºç›¸å…³å…³é”®å­—
            keywords = ['iptv', 'live', 'channel', 'playlist']
            for keyword in keywords:
                if keyword in url_lower:
                    return True
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å…³é”®å­—ï¼Œä¸å¤„ç†ä¸ºå¤–éƒ¨ç›´æ’­æº
            return False
                
        return False
        
    def read_json_file(self, progress_callback=None):
        """è¯»å–JSONæ ¼å¼æ–‡ä»¶ï¼Œè§£æé¢‘é“ä¿¡æ¯å’Œåˆ†ç±»ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        # æ¸…é™¤å·²å¤„ç†çš„å¤–éƒ¨URLç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è§£æéƒ½æ˜¯å…¨æ–°å¼€å§‹
        self.processed_external_urls.clear()
        
        channels = []
        categories = []
        processed_count = 0
        
        try:
            if self.debug:
                print(f"[è°ƒè¯•] æ­£åœ¨è§£æJSONæ–‡ä»¶: {self.input_file}")
            
            # è¯»å–JSONæ–‡ä»¶
            with open(self.input_file, 'r', encoding='utf-8-sig', errors='replace') as f:
                data = json.load(f)
            
            # é€’å½’æå–é¢‘é“ä¿¡æ¯çš„è¾…åŠ©å‡½æ•°
            def extract_channels(obj, category=None):
                if isinstance(obj, dict):
                    # æ£€æŸ¥æ˜¯å¦ä¸ºé¢‘é“å¯¹è±¡
                    if 'name' in obj and 'url' in obj:
                        name = obj['name']
                        # ä»é¢‘é“åç§°ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        resolution_match = re.search(r'\[(\d+\*\d+)\]', name)
                        resolution = resolution_match.group(1) if resolution_match else None
                        return [{
                            'name': name,
                            'url': obj['url'],
                            'category': obj.get('category') or category or 'æœªåˆ†ç±»',
                            'resolution_from_name': resolution
                        }]
                    elif 'channel' in obj and 'url' in obj:
                        name = obj['channel']
                        # ä»é¢‘é“åç§°ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        resolution_match = re.search(r'\[(\d+\*\d+)\]', name)
                        resolution = resolution_match.group(1) if resolution_match else None
                        return [{
                            'name': name,
                            'url': obj['url'],
                            'category': obj.get('category') or category or 'æœªåˆ†ç±»',
                            'resolution_from_name': resolution
                        }]
                    
                    # é€’å½’å¤„ç†å­—å…¸
                    result = []
                    for key, value in obj.items():
                        # å¦‚æœå€¼æ˜¯åˆ—è¡¨æˆ–å­—å…¸ï¼Œé€’å½’å¤„ç†
                        if isinstance(value, (list, dict)):
                            # å°è¯•å°†é”®ä½œä¸ºåˆ†ç±»å
                            result.extend(extract_channels(value, key))
                        # æ£€æŸ¥æ˜¯å¦æœ‰channelsã€listæˆ–dataå­—æ®µ
                        elif key in ['channels', 'list', 'data']:
                            result.extend(extract_channels(value))
                    return result
                elif isinstance(obj, list):
                    # é€’å½’å¤„ç†åˆ—è¡¨
                    result = []
                    for item in obj:
                        result.extend(extract_channels(item, category))
                    return result
                return []
            
            # æå–æ‰€æœ‰é¢‘é“
            all_channels = extract_channels(data)
            total_channels = len(all_channels)
            
            if self.debug:
                print(f"[è°ƒè¯•] ä»JSONæ–‡ä»¶ä¸­æå–åˆ° {total_channels} ä¸ªé¢‘é“")
            
            # å¤„ç†æå–åˆ°çš„é¢‘é“
            for channel in all_channels:
                # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
                if self.stop_requested:
                    print("è§£ææ–‡ä»¶è¿‡ç¨‹å·²è¢«åœæ­¢")
                    break
                    
                # æ£€æŸ¥é¢‘é“ä¿¡æ¯å®Œæ•´æ€§
                if channel.get('name') and channel.get('url'):
                    channels.append(channel)
                    
                    # æ›´æ–°åˆ†ç±»åˆ—è¡¨
                    category = channel.get('category', 'æœªåˆ†ç±»')
                    if category not in categories:
                        categories.append(category)
                    
                    processed_count += 1
                    
                    # å‘é€è¿›åº¦æ›´æ–°
                    if progress_callback:
                        progress = int((processed_count / max(total_channels, 1)) * 100)
                        progress_callback({
                            'progress': progress,
                            'total_channels': max(total_channels, 1),
                            'processed': processed_count,
                            'channel': channel,
                            'stage': 'parsing'
                        })
        
        except json.JSONDecodeError as e:
            if self.debug:
                print(f"[è°ƒè¯•] JSONè§£æé”™è¯¯: {str(e)}")
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] è¯»å–JSONæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        # ç¡®ä¿æ‰€æœ‰åˆ†ç±»éƒ½å­˜åœ¨
        if not categories:
            categories.append('æœªåˆ†ç±»')
        
        self.channels = channels
        self.categories = categories
        return channels, categories

    def _handle_external_url(self, url, default_category, progress_callback=None, processed_count=0, total_channels=0):
        """å¤„ç†å¤–éƒ¨URLï¼Œä¸‹è½½å¹¶è§£æç›´æ’­æºæ–‡ä»¶ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        external_channels = []
        external_categories = []
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªURLï¼Œé¿å…é‡å¤æ·»åŠ 
        if url in self.processed_external_urls:
            if self.debug:
                print(f"[è°ƒè¯•] å¤–éƒ¨URLå·²å¤„ç†è¿‡ï¼Œè·³è¿‡: {url}")
            return external_channels, external_categories, processed_count
        
        # æ ‡è®°URLä¸ºå·²å¤„ç†
        self.processed_external_urls.add(url)
        
        try:
            if self.debug:
                print(f"[è°ƒè¯•] å¤„ç†å¤–éƒ¨URL: {url}")
            
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                return external_channels, external_categories, processed_count
            
            # ä¸‹è½½å¤–éƒ¨æ–‡ä»¶
            temp_file = self._download_url(url)
            
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                os.remove(temp_file)
                return external_channels, external_categories, processed_count
            
            # æ£€æµ‹æ–‡ä»¶ç±»å‹
            file_ext = os.path.splitext(temp_file)[1].lower()
            
            if file_ext in ['.m3u', '.m3u8']:
                # ä½¿ç”¨read_m3u_fileæ–¹æ³•è§£æ
                temp_validator = IPTVValidator(temp_file, debug=self.debug)
                temp_validator.file_type = 'm3u'
                # å°†å·²å¤„ç†URLé›†åˆä¼ é€’ç»™ä¸´æ—¶éªŒè¯å™¨ï¼Œé¿å…é‡å¤å¤„ç†
                temp_validator.processed_external_urls = self.processed_external_urls.copy()
                external_channels, external_categories = temp_validator.read_m3u_file(progress_callback)
            elif file_ext == '.txt':
                # ä½¿ç”¨read_txt_fileæ–¹æ³•è§£æï¼ˆé€’å½’ï¼‰
                temp_validator = IPTVValidator(temp_file, debug=self.debug)
                temp_validator.file_type = 'txt'
                # å°†å·²å¤„ç†URLé›†åˆä¼ é€’ç»™ä¸´æ—¶éªŒè¯å™¨ï¼Œé¿å…é‡å¤å¤„ç†
                temp_validator.processed_external_urls = self.processed_external_urls.copy()
                external_channels, external_categories = temp_validator.read_txt_file(progress_callback)
            elif file_ext == '.json':
                # ä½¿ç”¨read_json_fileæ–¹æ³•è§£æ
                temp_validator = IPTVValidator(temp_file, debug=self.debug)
                temp_validator.file_type = 'json'
                # å°†å·²å¤„ç†URLé›†åˆä¼ é€’ç»™ä¸´æ—¶éªŒè¯å™¨ï¼Œé¿å…é‡å¤å¤„ç†
                temp_validator.processed_external_urls = self.processed_external_urls.copy()
                external_channels, external_categories = temp_validator.read_json_file(progress_callback)
            
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                os.remove(temp_file)
                return external_channels, external_categories, processed_count
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_file)
            
            # å¦‚æœå¤–éƒ¨æ–‡ä»¶æ²¡æœ‰åˆ†ç±»ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»
            for channel in external_channels:
                if not channel.get('category'):
                    channel['category'] = default_category
                # å‘é€è¿›åº¦æ›´æ–°
                if progress_callback:
                    processed_count += 1
                    progress = int((processed_count / max(total_channels, processed_count)) * 100)
                    progress_callback({
                        'progress': progress,
                        'total_channels': max(total_channels, processed_count),
                        'processed': processed_count,
                        'channel': channel
                    })
            
            if self.debug:
                print(f"[è°ƒè¯•] ä»å¤–éƒ¨URLè§£æåˆ° {len(external_channels)} ä¸ªé¢‘é“")
                
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] å¤„ç†å¤–éƒ¨URLå‡ºé”™: {str(e)}")
            # å¤–éƒ¨URLå¤„ç†å¤±è´¥ï¼Œå¿½ç•¥è¯¥URL
        
        return external_channels, external_categories, processed_count

    def check_url_validity(self, url):
        """æ£€æŸ¥URLçš„æœ‰æ•ˆæ€§"""
        try:
            # å¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„URLï¼Œå¦‚$ç¬¦å·ï¼ˆé€šå¸¸æ˜¯ç”µè§†ç«¯çš„æ ‡è¯†ï¼‰
            if '$' in url:
                # ç§»é™¤$ç¬¦å·åŠå…¶åé¢çš„å†…å®¹ï¼Œåªä¿ç•™å‰é¢çš„URLéƒ¨åˆ†
                url = url.split('$')[0]
                if self.debug:
                    print(f"[è°ƒè¯•] å¤„ç†åŒ…å«$ç¬¦å·çš„URL: {url}")

            # æ£€æµ‹æ˜¯å¦åŒ…å«åŠ¨æ€å‚æ•°ï¼ˆå¦‚{PSID}ã€{TARGETOPT}ç­‰ï¼ŒåŒ…æ‹¬URLç¼–ç å½¢å¼%7BPSID%7Dï¼‰
            has_dynamic_params = re.search(r'(\{[A-Z_]+\}|%7B[A-Z_]+%7D)', url)
            if has_dynamic_params and self.debug:
                print(f"[è°ƒè¯•] æ£€æµ‹åˆ°åŒ…å«åŠ¨æ€å‚æ•°çš„URL: {url}")

            # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œæ–‡ä»¶ä¸­çš„çº¿è·¯éƒ½æ˜¯ç”µè§†ä¸Šèƒ½æ‰“å¼€æ’­æ”¾çš„é¢‘é“çº¿è·¯
            # æ‰€ä»¥æˆ‘ä»¬å¯¹URLéªŒè¯æ›´åŠ å®½æ¾ï¼Œåªè¦URLä¸ä¸ºç©ºå°±è§†ä¸ºæœ‰æ•ˆ
            if url.strip():
                if self.debug:
                    print(f"[è°ƒè¯•] URLä¸ä¸ºç©ºï¼Œè§†ä¸ºæœ‰æ•ˆ: {url}")
                return True
            
            # åªæœ‰ç©ºURLæ‰è§†ä¸ºæ— æ•ˆ
            if self.debug:
                print(f"[è°ƒè¯•] URLä¸ºç©ºï¼Œè§†ä¸ºæ— æ•ˆ: {url}")
            return False
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] æ£€æŸ¥URLæœ‰æ•ˆæ€§æ—¶å‡ºé”™: {type(e).__name__}: {e}")
            # å¦‚æœå‘ç”Ÿä»»ä½•å¼‚å¸¸ï¼Œåªè¦URLä¸ä¸ºç©ºå°±è§†ä¸ºæœ‰æ•ˆ
            if url.strip():
                if self.debug:
                    print(f"[è°ƒè¯•] å¼‚å¸¸å¤„ç†ä¸­URLä¸ä¸ºç©ºï¼Œè§†ä¸ºæœ‰æ•ˆ: {url}")
                return True
            return False


    
    def get_resolution(self, url):
        """è·å–è§†é¢‘åˆ†è¾¨ç‡ï¼Œä½¿ç”¨è¿›ç¨‹æ± æé«˜æ€§èƒ½"""
        try:
            # æ£€æŸ¥ffprobeæ˜¯å¦å¯ç”¨
            if not self.ffprobe_available:
                return None

            # æ”¯æŒæ›´å¤šåè®®å’Œæ ¼å¼çš„åˆ†è¾¨ç‡æ£€æµ‹
            supported_protocols = [
                '.m3u8', 'm3u8', 'rtsp://', 'rtmp://', 
                'udp://', 'rtp://', 'http://', 'https://'
            ]
            
            # æ£€æŸ¥URLæ˜¯å¦åŒ…å«ä»»ä½•æ”¯æŒçš„åè®®æˆ–æ ¼å¼
            if not any(protocol in url for protocol in supported_protocols):
                return None

            # ä½¿ç”¨è¿›ç¨‹æ± æ‰§è¡Œffprobeå‘½ä»¤
            future = self.ffprobe_pool.submit(_ffprobe_get_resolution, url, self.timeouts['ffprobe'])
            resolution = future.result()
            return resolution

        except Exception:
            return None

    def process_channel(self, channel, thread_id):
        """å¤„ç†å•ä¸ªé¢‘é“ï¼šéªŒè¯URLå¹¶æ£€æµ‹åˆ†è¾¨ç‡ï¼ŒåŒ…å«çº¿ç¨‹å·ä¿¡æ¯"""
        result = {
            'name': channel['name'],
            'url': channel['url'],
            'category': channel.get('category', 'æœªåˆ†ç±»'),
            'thread_id': thread_id,
            'valid': False,
            'resolution': None,
            'status': 'invalid'  # é»˜è®¤çŠ¶æ€ä¸ºæ— æ•ˆ
        }
        
        try:
            valid = self.check_url_validity(channel['url'])
            if not valid:
                return result

            result['valid'] = True
            result['status'] = 'valid'  # è®¾ç½®ä¸ºæœ‰æ•ˆçŠ¶æ€
            
            try:
                # æ£€æµ‹åˆ†è¾¨ç‡
                resolution = self.get_resolution(channel['url'])
                
                # å¦‚æœffprobeæ£€æµ‹å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä»é¢‘é“åç§°ä¸­æå–çš„åˆ†è¾¨ç‡
                if not resolution and channel.get('resolution_from_name'):
                    resolution = channel['resolution_from_name']
                    
                result['resolution'] = resolution
                
                if resolution:
                    # æ£€æŸ¥é¢‘é“åç§°æ˜¯å¦å·²ç»åŒ…å«åˆ†è¾¨ç‡ä¿¡æ¯
                    if f"[{resolution}]" not in channel['name']:
                        result['name_with_resolution'] = f"{channel['name']}[{resolution}]"
                    else:
                        result['name_with_resolution'] = channel['name']
                else:
                    result['name_with_resolution'] = channel['name']
            except concurrent.futures.TimeoutError:
                # æ•è·åˆ†è¾¨ç‡æ£€æµ‹è¶…æ—¶å¼‚å¸¸
                result['status'] = 'timeout'  # è®¾ç½®ä¸ºè¶…æ—¶çŠ¶æ€
                # è¶…æ—¶æƒ…å†µä¸‹ä¹Ÿå°è¯•ä½¿ç”¨ä»åç§°ä¸­æå–çš„åˆ†è¾¨ç‡
                if channel.get('resolution_from_name'):
                    result['resolution'] = channel['resolution_from_name']
                    result['name_with_resolution'] = channel['name']
                else:
                    result['name_with_resolution'] = channel['name']
            except Exception as e:
                if self.debug:
                    print(f"[è°ƒè¯•] æ£€æµ‹é¢‘é“ {channel['name']} åˆ†è¾¨ç‡æ—¶å‡ºé”™: {type(e).__name__}: {e}")
                # åˆ†è¾¨ç‡æ£€æµ‹å¤±è´¥ä¸å½±å“URLæœ‰æ•ˆæ€§åˆ¤æ–­
                # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿå°è¯•ä½¿ç”¨ä»åç§°ä¸­æå–çš„åˆ†è¾¨ç‡
                if channel.get('resolution_from_name'):
                    result['resolution'] = channel['resolution_from_name']
                    result['name_with_resolution'] = channel['name']
                else:
                    result['name_with_resolution'] = channel['name']

        except concurrent.futures.TimeoutError:
            # æ•è·URLéªŒè¯è¶…æ—¶å¼‚å¸¸
            result['status'] = 'timeout'  # è®¾ç½®ä¸ºè¶…æ—¶çŠ¶æ€
            # è¶…æ—¶æƒ…å†µä¸‹ä¹Ÿå°è¯•ä½¿ç”¨ä»åç§°ä¸­æå–çš„åˆ†è¾¨ç‡
            if channel.get('resolution_from_name'):
                result['resolution'] = channel['resolution_from_name']
            result['name_with_resolution'] = channel['name']
        except Exception as e:
            if self.debug:
                print(f"[è°ƒè¯•] å¤„ç†é¢‘é“ {channel['name']} æ—¶å‡ºé”™: {type(e).__name__}: {e}")
            # å…¶ä»–å¼‚å¸¸ä¿æŒé¢‘é“ä¸ºæ— æ•ˆ
            # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿå°è¯•ä½¿ç”¨ä»åç§°ä¸­æå–çš„åˆ†è¾¨ç‡
            if channel.get('resolution_from_name'):
                result['resolution'] = channel['resolution_from_name']
            result['name_with_resolution'] = channel['name']

        return result

    def validate_channels(self, progress_callback=None):
        """æ‰¹é‡éªŒè¯æ‰€æœ‰é¢‘é“ï¼Œåˆ†æ‰¹æ¬¡å¤„ç†ä»¥é¿å…å ç”¨è¿‡å¤šèµ„æº"""
        all_results = []
        valid_channels = []
        resolution_valid_channels = []  # å­˜å‚¨æ£€æµ‹åˆ°åˆ†è¾¨ç‡çš„æœ‰æ•ˆé¢‘é“
        total_channels = len(self.channels)
        processed_count = 0
        
        # æ¸…é™¤å·²å¤„ç†çš„å¤–éƒ¨URLç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡éªŒè¯éƒ½æ˜¯å…¨æ–°å¼€å§‹
        self.processed_external_urls.clear()
        
        # åˆ†æ‰¹æ¬¡å¤„ç†é¢‘é“
        for i in range(0, total_channels, self.batch_size):
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if self.stop_requested:
                print("éªŒè¯è¿‡ç¨‹å·²è¢«åœæ­¢")
                break
                
            batch_start = i
            batch_end = min(i + self.batch_size, total_channels)
            
            # å‘é€æ‰¹æ¬¡å¤„ç†å¼€å§‹çš„è¿›åº¦æ›´æ–°
            if progress_callback:
                progress = int((processed_count / total_channels) * 100)
                progress_callback({
                    'progress': progress,
                    'total_channels': total_channels,
                    'processed': processed_count,
                    'message': f'å¼€å§‹å¤„ç†æ‰¹æ¬¡ {batch_start + 1}-{batch_end} / {total_channels}',
                    'stage': 'batch_processing'
                })
            
            batch_channels = self.channels[batch_start:batch_end]
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_channel = {executor.submit(self.process_channel, channel, thread_id + batch_start): channel for thread_id, channel in enumerate(batch_channels)}
                for future in concurrent.futures.as_completed(future_to_channel):
                    # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
                    if self.stop_requested:
                        executor.shutdown(wait=False)
                        print("éªŒè¯è¿‡ç¨‹å·²è¢«åœæ­¢")
                        break
                        
                    result = future.result()
                    all_results.append(result)
                    processed_count += 1
                    
                    # å‘é€å®æ—¶è¿›åº¦
                    if progress_callback:
                        progress = int((processed_count / total_channels) * 100)
                        progress_callback({
                            'progress': progress,
                            'total_channels': total_channels,
                            'processed': processed_count,
                            'channel': result
                        })
                    
                    if result['valid']:
                        valid_channels.append(result)
                        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†è¾¨ç‡ä¿¡æ¯
                        if result.get('resolution'):
                            resolution_valid_channels.append(result)

        # å‘é€å®Œæˆé€šçŸ¥
        if progress_callback:
            progress_callback({
                'progress': 100 if processed_count == total_channels else processed_count,
                'total_channels': total_channels,
                'processed': processed_count,
                'valid_count': len(valid_channels),
                'resolution_valid_count': len(resolution_valid_channels),  # åˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“æ•°é‡
                'invalid_count': processed_count - len(valid_channels),
                'status': 'completed' if not self.stop_requested else 'stopped'
            })
        
        self.all_results = all_results
        return valid_channels

    def generate_m3u_output(self, valid_channels):
        """ç”ŸæˆM3Uæ ¼å¼çš„è¾“å‡ºæ–‡ä»¶"""
        # æŒ‰åˆ†ç±»åˆ†ç»„é¢‘é“
        channels_by_category = {category: [] for category in self.categories}
        # ç¡®ä¿æ‰€æœ‰åˆ†ç±»éƒ½å­˜åœ¨ï¼ŒåŒ…æ‹¬æ— åˆ†ç±»çš„é¢‘é“
        if 'æœªåˆ†ç±»' not in channels_by_category:
            channels_by_category['æœªåˆ†ç±»'] = []
            self.categories.append('æœªåˆ†ç±»')
        
        for channel in valid_channels:
            category = channel.get('category', 'æœªåˆ†ç±»')
            if category in channels_by_category:
                channels_by_category[category].append(channel)

        # ç”ŸæˆM3Uå†…å®¹
        content = ['#EXTM3U']
        for category in self.categories:
            for channel in channels_by_category[category]:
                content.append(f"#EXTINF:-1 group-title=\"{channel['category']}\",{channel['name_with_resolution']}")
                content.append(channel['url'])

        # å†™å…¥æ–‡ä»¶
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))

        return self.output_file

    def generate_txt_output(self, valid_channels):
        """ç”ŸæˆTXTæ ¼å¼çš„è¾“å‡ºæ–‡ä»¶"""
        # æŒ‰åˆ†ç±»åˆ†ç»„é¢‘é“
        channels_by_category = {}
        
        # é¦–å…ˆå°†æ‰€æœ‰æœ‰æ•ˆåˆ†ç±»æ·»åŠ åˆ°å­—å…¸ä¸­
        for category in self.categories:
            if category not in channels_by_category:
                channels_by_category[category] = []
        
        # éå†æ‰€æœ‰æœ‰æ•ˆé¢‘é“ï¼Œæ·»åŠ åˆ°å¯¹åº”çš„åˆ†ç±»ä¸­
        for channel in valid_channels:
            category = channel['category']
            if category not in channels_by_category:
                channels_by_category[category] = []
                # å¦‚æœè¿™æ˜¯ä¸€ä¸ªæ–°çš„åˆ†ç±»ï¼Œå°†å…¶æ·»åŠ åˆ°åˆ†ç±»åˆ—è¡¨ä¸­
                if category not in self.categories:
                    self.categories.append(category)
            channels_by_category[category].append(channel)

        # ç”ŸæˆTXTå†…å®¹
        content = []
        for category in self.categories:
            if category in channels_by_category and channels_by_category[category]:
                content.append(f"#{category}#,genre#")
                for channel in channels_by_category[category]:
                    content.append(f"{channel['name_with_resolution']},{channel['url']}")

        # å†™å…¥æ–‡ä»¶
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))
        
        return self.output_file
        
    def generate_json_output(self, valid_channels):
        """ç”ŸæˆJSONæ ¼å¼çš„è¾“å‡ºæ–‡ä»¶"""
        # æŒ‰åˆ†ç±»åˆ†ç»„é¢‘é“
        channels_by_category = {}
        
        # éå†æ‰€æœ‰æœ‰æ•ˆé¢‘é“ï¼Œæ·»åŠ åˆ°å¯¹åº”çš„åˆ†ç±»ä¸­
        for channel in valid_channels:
            category = channel['category']
            if category not in channels_by_category:
                channels_by_category[category] = []
            channels_by_category[category].append({
                'name': channel['name_with_resolution'],
                'url': channel['url'],
                'category': category
            })

        # åˆ›å»ºJSONç»“æ„
        json_data = {
            'total_channels': len(valid_channels),
            'categories': list(channels_by_category.keys()),
            'channels': []
        }
        
        # æ·»åŠ æ‰€æœ‰é¢‘é“
        for channel in valid_channels:
            json_data['channels'].append({
                'name': channel['name_with_resolution'],
                'url': channel['url'],
                'category': channel['category']
            })

        # å†™å…¥æ–‡ä»¶
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        return self.output_file
        
    def get_all_results(self):
        """è·å–æ‰€æœ‰é¢‘é“çš„éªŒè¯ç»“æœï¼ŒåŒ…æ‹¬æœ‰æ•ˆå’Œæ— æ•ˆçš„"""
        return getattr(self, 'all_results', [])
        
    def generate_output_files(self):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶ï¼Œæ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„æ–¹æ³•"""
        # è·å–æœ‰æ•ˆé¢‘é“
        valid_channels = [channel for channel in self.all_results if channel['valid']]
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        if self.file_type == 'm3u':
            output_file = self.generate_m3u_output(valid_channels)
        elif self.file_type == 'json':
            output_file = self.generate_json_output(valid_channels)
        else:
            output_file = self.generate_txt_output(valid_channels)
        
        # ç”Ÿæˆåˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“çš„è¾“å‡ºæ–‡ä»¶
        resolution_valid_channels = [channel for channel in valid_channels if channel.get('resolution')]
        if resolution_valid_channels:
            # åˆ›å»ºå¸¦åˆ†è¾¨ç‡æ ‡è®°çš„è¾“å‡ºæ–‡ä»¶å
            base_name, ext = os.path.splitext(output_file)
            resolution_output_file = f"{base_name}_resolution{ext}"
            
            # ä¿å­˜åŸå§‹è¾“å‡ºæ–‡ä»¶åï¼Œä¸´æ—¶æ›¿æ¢ä¸ºåˆ†è¾¨ç‡è¾“å‡ºæ–‡ä»¶å
            original_output_file = self.output_file
            self.output_file = resolution_output_file
            
            # ç”Ÿæˆåˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“æ–‡ä»¶
            if self.file_type == 'm3u':
                self.generate_m3u_output(resolution_valid_channels)
            elif self.file_type == 'json':
                self.generate_json_output(resolution_valid_channels)
            else:
                self.generate_txt_output(resolution_valid_channels)
            
            # æ¢å¤åŸå§‹è¾“å‡ºæ–‡ä»¶å
            self.output_file = original_output_file
            
            print(f"åˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ: {resolution_output_file}")
        
        return output_file

    def run(self):
        """è¿è¡ŒéªŒè¯æµç¨‹"""
        print(f"å¼€å§‹éªŒè¯æ–‡ä»¶: {self.input_file}")
        print(f"æ–‡ä»¶ç±»å‹: {self.file_type}")
        
        # æ£€æŸ¥ffprobeæ˜¯å¦å¯ç”¨
        if not self.ffprobe_available:
            print("è­¦å‘Š: æœªæ£€æµ‹åˆ°ffprobeï¼Œå°†è·³è¿‡è§†é¢‘åˆ†è¾¨ç‡æ£€æµ‹")
            print("è¯·å®‰è£…FFmpegå¹¶æ·»åŠ åˆ°ç³»ç»ŸPATHä»¥å¯ç”¨åˆ†è¾¨ç‡æ£€æµ‹åŠŸèƒ½")

        # è¯»å–æ–‡ä»¶
        if self.file_type == 'm3u':
            self.read_m3u_file()
        elif self.file_type == 'json':
            self.read_json_file()
        else:
            self.read_txt_file()

        print(f"å…±è§£æåˆ° {len(self.channels)} ä¸ªé¢‘é“ï¼Œ{len(self.categories)} ä¸ªåˆ†ç±»")
        
        # å¦‚æœæ²¡æœ‰è§£æåˆ°é¢‘é“
        if not self.channels:
            print("é”™è¯¯: æ²¡æœ‰ä»æ–‡ä»¶ä¸­è§£æåˆ°ä»»ä½•é¢‘é“")
            print("æç¤º: è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿æ˜¯æ ‡å‡†çš„M3Uæˆ–TXTæ ¼å¼")
            return None

        # éªŒè¯é¢‘é“
        start_time = time.time()
        valid_channels = self.validate_channels()
        end_time = time.time()

        print(f"éªŒè¯å®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’")
        print(f"æœ‰æ•ˆé¢‘é“æ•°: {len(valid_channels)}")
        # è®¡ç®—åˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“æ•°
        resolution_valid_channels = [channel for channel in self.all_results if channel['valid'] and channel.get('resolution')]
        print(f"åˆ†è¾¨ç‡æœ‰æ•ˆé¢‘é“æ•°: {len(resolution_valid_channels)}")
        if len(self.channels) > 0:
            print(f"æœ‰æ•ˆç‡: {len(valid_channels) / len(self.channels) * 100:.2f}%")
        else:
            print("æœ‰æ•ˆç‡: 0.00%")

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        if valid_channels:
            output_file = self.generate_output_files()
            print(f"è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
            return output_file
        else:
            print("\næ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç›´æ’­æº")
            print("\nğŸ” å¯èƒ½çš„åŸå› :")
            print("1. ç½‘ç»œç¯å¢ƒé™åˆ¶ï¼šå¯èƒ½æ˜¯é˜²ç«å¢™ã€ä»£ç†æˆ–ç½‘ç»œç­–ç•¥é˜»æ­¢äº†å¯¹ç›´æ’­æºçš„è®¿é—®")
            print("2. DNSè§£æå¤±è´¥ï¼šæ— æ³•è§£æç›´æ’­æºæœåŠ¡å™¨çš„åŸŸå")
            print("3. URLå·²å¤±æ•ˆï¼šç›´æ’­æºæœåŠ¡å™¨å¯èƒ½å·²ç»å…³é—­æˆ–æ›´æ”¹äº†åœ°å€")
            print("4. ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼šç½‘ç»œå»¶è¿Ÿæˆ–ä¸¢åŒ…å¯¼è‡´è¿æ¥è¶…æ—¶")
            print("5. URLæ ¼å¼é”™è¯¯ï¼šè¯·ç¡®ä¿æ‰€æœ‰URLéƒ½åŒ…å«æ­£ç¡®çš„åè®®ï¼ˆhttp/https/rtsp/rtmp/mmsï¼‰")
            
            print("\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼šç¡®ä¿æ‚¨çš„è®¡ç®—æœºå¯ä»¥æ­£å¸¸è®¿é—®äº’è”ç½‘")
            print("2. éªŒè¯URLæœ‰æ•ˆæ€§ï¼šæ‰‹åŠ¨æµ‹è¯•å‡ ä¸ªURLæ˜¯å¦å¯ä»¥è®¿é—®")
            print("3. æ›´æ¢ç›´æ’­æºï¼šå°è¯•ä½¿ç”¨å…¶ä»–å¯é çš„ç›´æ’­æºæä¾›å•†")
            print("4. è°ƒæ•´è¶…æ—¶æ—¶é—´ï¼šä½¿ç”¨ -t å‚æ•°å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œä¾‹å¦‚ï¼š-t 10")
            print("5. æ£€æŸ¥URLæ ¼å¼ï¼šç¡®ä¿æ‰€æœ‰URLéƒ½ç¬¦åˆæ ‡å‡†æ ¼å¼")
            
            print("\nğŸ“ ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨æœ‰æ•ˆçš„ç›´æ’­æº")
            print("æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä»¥ä¸‹æ ¼å¼çš„M3Uæ–‡ä»¶ï¼š")
            print("#EXTM3U")
            print("#EXTINF:-1 group-title=\"æµ‹è¯•\",æµ‹è¯•é¢‘é“")
            print("http://example.com/valid_stream.m3u8")
            
        # å…³é—­ffprobeè¿›ç¨‹æ± 
        if hasattr(self, 'ffprobe_pool') and self.ffprobe_pool:
            self.ffprobe_pool.shutdown()
            
        return None


def validate_file(input_file, output_file=None, max_workers=20, timeout=5, debug=False):
    """ä¾¿æ·å‡½æ•°ï¼šéªŒè¯å•ä¸ªæ–‡ä»¶"""
    validator = IPTVValidator(input_file, output_file, max_workers, timeout, debug)
    output_file = validator.run()
    return output_file, validator.get_all_results()


def validate_all_files(directory='.', max_workers=20, timeout=5, debug=False):
    """ä¾¿æ·å‡½æ•°ï¼šéªŒè¯ç›®å½•ä¸‹æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶"""
    supported_extensions = ('.m3u', '.m3u8', '.txt')
    files_to_validate = []

    for filename in os.listdir(directory):
        if filename.endswith(supported_extensions) and not filename.endswith('_valid.m3u') and not filename.endswith('_valid.txt'):
            files_to_validate.append(os.path.join(directory, filename))

    print(f"æ‰¾åˆ° {len(files_to_validate)} ä¸ªæ–‡ä»¶éœ€è¦éªŒè¯")

    for file_path in files_to_validate:
        print(f"\n{'='*50}")
        output_file, _ = validate_file(file_path, max_workers=max_workers, timeout=timeout, debug=debug)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ç›´æ’­æºæœ‰æ•ˆæ€§éªŒè¯å·¥å…·')
    # åˆ›å»ºäº’æ–¥ç»„
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('-i', '--input', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    group.add_argument('-a', '--all', action='store_true', help='éªŒè¯å½“å‰ç›®å½•ä¸‹æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶')
    
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-w', '--workers', type=int, default=20, help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('-t', '--timeout', type=int, default=5, help='è¶…æ—¶æ—¶é—´(ç§’)')
    parser.add_argument('-d', '--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„éªŒè¯ä¿¡æ¯')

    args = parser.parse_args()

    if args.all:
        validate_all_files('.', args.workers, args.timeout, args.debug)
    else:
        output_file, _ = validate_file(args.input, args.output, args.workers, args.timeout, args.debug)
